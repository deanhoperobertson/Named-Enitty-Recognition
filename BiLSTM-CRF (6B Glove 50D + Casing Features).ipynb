{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bi-LSTM-CRF (6B Glove 50D  + Features)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deanhoperobertson/Named-Enitty-Recognition/blob/master/BiLSTM-CRF%20(6B%20Glove%2050D%20%2B%20Casing%20Features).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYs0s57M3jAf",
        "colab_type": "code",
        "outputId": "367d17b0-8030-4fee-8ecd-f63e523249b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "!sudo pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install sklearn_crfsuite\n",
        "!pip install keras==2.2.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-bamb4mz_\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-bamb4mz_\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.17.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=70e40282612df9ad1d69f0c0b4adafaf05027c61398f8db8fea23ebbff164329\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gnvcx11o/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.28.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/86/cfcd71edca9d25d3d331209a20f6314b6f3f134c29478f90559cee9ce091/python_crfsuite-0.9.6-cp36-cp36m-manylinux1_x86_64.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.6 sklearn-crfsuite-0.3.6\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvLtrysY3xZn",
        "colab_type": "code",
        "outputId": "3c07fcc6-fbf3-4014-d07d-d3f480deb38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#keras and tensorflow packages\n",
        "from keras.layers.merge import add\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional,concatenate\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy\n",
        "from keras_contrib.metrics import crf_accuracy\n",
        "\n",
        "\n",
        "#evaluation\n",
        "from sklearn_crfsuite.metrics import flat_classification_report,flat_f1_score,flat_precision_score"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ5UL1PL39-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import data from my github repo\n",
        "train_url = \"https://raw.githubusercontent.com/deanhoperobertson/Named-Enitty-Recognition/master/Data/train.txt\"\n",
        "test_url = \"https://raw.githubusercontent.com/deanhoperobertson/Named-Enitty-Recognition/master/Data/test.txt\"\n",
        "#valid_url = \"https://raw.githubusercontent.com/deanhoperobertson/Named-Enitty-Recognition/master/Data/valid.txt\"\n",
        "train = urllib.request.urlopen(train_url).read()\n",
        "test = urllib.request.urlopen(test_url).read()\n",
        "train = train.decode('utf-8')\n",
        "test = test.decode('utf-8')\n",
        "#valid = valid.decode('utf-8')\n",
        "\n",
        "def readstring(filename, meth):\n",
        "    f = filename.split('\\n')\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for line in f:\n",
        "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
        "            if len(sentence) > 0:\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "            continue\n",
        "        splits = line.split(' ')\n",
        "        if meth.lower()==\"numbers1\":\n",
        "            sentence.append([hasNumbers1(splits[0]), splits[-1].strip()])\n",
        "        elif meth.lower()==\"numbers2\":\n",
        "            sentence.append([hasNumbers2(splits[0]), splits[-1].strip()])\n",
        "        else:\n",
        "            sentence.append([splits[0], splits[-1].strip()])\n",
        "    if len(sentence) > 0:\n",
        "        sentences.append(sentence)\n",
        "        sentence = []\n",
        "    return sentences\n",
        "\n",
        "def hasNumbers1(inputString):\n",
        "    if re.search(r'\\d', inputString):\n",
        "        return \"__\"\n",
        "    else:return(inputString)\n",
        "\n",
        "def hasNumbers2(text):\n",
        "  if text.isdigit():\n",
        "      return \"1\"\n",
        "  elif re.search(r'\\d',text) and re.search(r'\\,|\\.',text):\n",
        "      return \"1\" \n",
        "  else:\n",
        "      if re.search(r'\\d', text):\n",
        "          return(re.sub('\\d','D', text))\n",
        "      else:\n",
        "          return text\n",
        "\n",
        "#preproces the txt file\n",
        "train_data = readstring(train,\"Numbers1\")\n",
        "test_data = readstring(test,\"Numbers1\")\n",
        "\n",
        "#create corpus\n",
        "corpus = train_data.copy()\n",
        "corpus.extend(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQSami9V4FbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reformat_data(data,meth):\n",
        "  if meth.lower() == \"data\":\n",
        "    i=0\n",
        "  else: i=1\n",
        "  train = []\n",
        "  output= []\n",
        "  for sentence in data:\n",
        "    words=[]\n",
        "    for x in sentence:\n",
        "      words.append(x[i])\n",
        "    train.append(words)\n",
        "\n",
        "  for i in train:\n",
        "    string = ' '.join(i)\n",
        "    output.append(string)\n",
        "  return output\n",
        "\n",
        "def get_max_length(corpus):\n",
        "  length = []\n",
        "  for sentence in corpus:\n",
        "    length.append(len(sentence))\n",
        "  return int(max(length))\n",
        "\n",
        "def number_of_tags(corpus):\n",
        "  tags=[]\n",
        "  for sentence in corpus:\n",
        "    for tag in sentence:\n",
        "      tags.append(tag[1])\n",
        "  return int(len(list(set(tags))))\n",
        "\n",
        "\n",
        "MAX_LEN = get_max_length(corpus)\n",
        "N_tags = number_of_tags(corpus)\n",
        "\n",
        "train = reformat_data(train_data,\"data\")\n",
        "test = reformat_data(test_data,\"data\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOyKFaZ64Piy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a tokenizer\n",
        "token_word = text.Tokenizer(char_level=False, lower=True, filters=\"}\", oov_token='UNK')\n",
        "token_word.fit_on_texts(train)\n",
        "\n",
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "X_train = sequence.pad_sequences(token_word.texts_to_sequences(train), maxlen=MAX_LEN,padding=\"post\")\n",
        "X_test = sequence.pad_sequences(token_word.texts_to_sequences(test), maxlen=MAX_LEN,padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "791RIPxLFdE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = reformat_data(train_data,\"tags\")\n",
        "test = reformat_data(test_data,\"tags\")\n",
        "\n",
        "# create a tokenizer\n",
        "token_tag = text.Tokenizer(char_level=False, lower=False, filters=\"}\")\n",
        "token_tag.fit_on_texts(train)\n",
        "\n",
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "Y = sequence.pad_sequences(token_tag.texts_to_sequences(train), maxlen=MAX_LEN,padding=\"post\")\n",
        "# One-Hot encode categorical labels\n",
        "Y_train = [to_categorical(i, num_classes=N_tags+1) for i in Y]\n",
        "\n",
        "Y = sequence.pad_sequences(token_tag.texts_to_sequences(test), maxlen=MAX_LEN,padding=\"post\")\n",
        "# One-Hot encode categorical labels\n",
        "Y_test = [to_categorical(i, num_classes=N_tags+1) for i in Y]\n",
        "\n",
        "#add padding \n",
        "token_tag.index_word[0]=\"PAD\"\n",
        "sub_label = list(token_tag.index_word.values())\n",
        "sub_label.remove('O')\n",
        "sub_label.remove('PAD')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADOS66iMHYkr",
        "colab_type": "code",
        "outputId": "bbfdbf1b-f3ba-4af5-ce49-583d4a4aa691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDX21YJbJy6N",
        "colab_type": "code",
        "outputId": "2be0e4c7-5181-4cd7-b670-bfad048b792e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "root_path = \"/content/drive/My Drive/glove.6B.50d.txt\"\n",
        "#root_path = \"/content/drive/My Drive/glove.6B.100d.txt\"\n",
        "#root_path = \"/content/drive/My Drive/glove.6B.200d.txt\"\n",
        "#root_path = \"/content/drive/My Drive/glove.6B.300d.txt\"\n",
        "#root_path = \"/content/drive/My Drive/glove.42B.300d.txt\"\n",
        "#root_path = \"/content/drive/My Drive/wiki-news-300d-1M.vec\"\n",
        "\n",
        "embeddings_index={}\n",
        "f = open(root_path, encoding = \"utf-8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OM5O7xy-h3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create emedding matrix\n",
        "EMBEDDING=int(root_path.split(\".\")[-2][:-1])\n",
        "word_index = token_word.word_index\n",
        "embedding_matrix = np.zeros((len(token_word.word_index) + 1, EMBEDDING))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all-zeros.\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHwzSe4s8cj",
        "colab_type": "code",
        "outputId": "d0d2f065-ea34-4175-f6cc-05044a29accd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "checks=[]\n",
        "words=[]\n",
        "for i in range(0,len(token_word.word_index)+1):\n",
        "  if embedding_matrix[i][0] == 0.0:\n",
        "    checks.append(1)\n",
        "    words.append(list(token_word.word_index.items())[i-1][0])\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "print(\"Missing words from Embeddings: %d (%.2f%%)\" %(len(checks),(len(checks)/len(token_word.word_index)*100)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Missing words from Embeddings: 1218 (7.10%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0G18EdzTSqI",
        "colab_type": "text"
      },
      "source": [
        "## Create Casing Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b0O3b-HTRfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getCasing(word, caseLookup):   \n",
        "    casing = 'other'\n",
        "    \n",
        "    numDigits = 0\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            numDigits += 1\n",
        "            \n",
        "    digitFraction = numDigits / float(len(word))\n",
        "    \n",
        "    if word.isdigit(): #Is a digit\n",
        "        casing = 'numeric'\n",
        "    elif digitFraction > 0.5:\n",
        "        casing = 'mainly_numeric'\n",
        "    elif word.islower(): #All lower case\n",
        "        casing = 'allLower'\n",
        "    elif word.isupper(): #All upper case\n",
        "        casing = 'allUpper'\n",
        "    elif word[0].isupper(): #is a title, initial char upper, then all lower\n",
        "        casing = 'initialUpper'\n",
        "    elif numDigits > 0:\n",
        "        casing = 'contains_digit'  \n",
        "    return caseLookup[casing]\n",
        "\n",
        "case2Idx = {'numeric': 7, 'allLower':1, 'allUpper':2, 'initialUpper':3, 'other':4, \n",
        "            'mainly_numeric':5, 'contains_digit': 6, 'PADDING_TOKEN':0}\n",
        "\n",
        "caseEmbeddings = np.identity(len(case2Idx), dtype='float32')\n",
        "\n",
        "\n",
        "X_cas = []\n",
        "for sentence in train_data:\n",
        "    sent_seq = []\n",
        "    for i in range(MAX_LEN):\n",
        "        word_seq = []\n",
        "        try:\n",
        "          word_seq.append(getCasing(sentence[i][0],case2Idx))\n",
        "        except:\n",
        "          word_seq.append(case2Idx.get('PADDING_TOKEN'))\n",
        "        sent_seq.append(word_seq)\n",
        "    X_cas.append(np.array(sent_seq))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLUxQqI8Md4N",
        "colab_type": "text"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJXcEXJYMg4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "25f0b980-4742-44d6-b07f-78056a9c07f9"
      },
      "source": [
        "# Model definition\n",
        "\n",
        "words_in = Input(shape=(MAX_LEN,), name=\"Input_Words\")\n",
        "casing_in = Input(shape=(MAX_LEN,), name=\"Input_Casings\")\n",
        "\n",
        "word_emb = Embedding(input_dim=len(token_word.word_index) + 1,output_dim=EMBEDDING,\n",
        "                     weights=[embedding_matrix],input_length=MAX_LEN,\n",
        "                     trainable=False,mask_zero=True)(words_in)\n",
        "\n",
        "# casing_emb = TimeDistributed(Embedding(input_dim=caseEmbeddings.shape[0],output_dim=caseEmbeddings.shape[1],\n",
        "#                        weights=[caseEmbeddings], trainable=False, mask_zero=True))(casing_in)\n",
        "\n",
        "casing_emb = Embedding(input_dim=caseEmbeddings.shape[0],output_dim=caseEmbeddings.shape[1],\n",
        "                       weights=[caseEmbeddings], trainable=False, mask_zero=True)(casing_in)\n",
        "\n",
        "# character LSTM to get word encodings by characters\n",
        "# cas_enc = TimeDistributed(LSTM(units=20, return_sequences=False, #20\n",
        "#                                 recurrent_dropout=0.5))(casing_emb) #0.3/0.5\n",
        "\n",
        "model_2 = concatenate([word_emb,casing_emb])\n",
        "model_2 = Bidirectional(LSTM(units=300, return_sequences=True,\n",
        "                           recurrent_dropout=0.1, dropout=0.3))(model_2) \n",
        "\n",
        "model_2 = TimeDistributed(Dense(50, activation=\"relu\"))(model_2)\n",
        "crf = CRF(N_tags+1)  # CRF layer\n",
        "out = crf(model_2)  # output\n",
        "model_2 = Model([words_in, casing_in], out)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA9_8iSPMiyn",
        "colab_type": "code",
        "outputId": "911189a0-8ffd-4ee5-fc29-6958ec8ffe32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adam=optimizers.Adam(clipvalue=0.5)\n",
        "\n",
        "model_2.compile(optimizer=adam, loss=crf_loss,metrics=[crf_viterbi_accuracy])\n",
        "model_2.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input_Words (InputLayer)        (None, 124)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input_Casings (InputLayer)      (None, 124)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 124, 50)      858250      Input_Words[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 124, 8)       64          Input_Casings[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 124, 58)      0           embedding_1[0][0]                \n",
            "                                                                 embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 124, 600)     861600      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 124, 50)      30050       bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "crf_1 (CRF)                     (None, 124, 9)       558         time_distributed_1[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 1,750,522\n",
            "Trainable params: 892,208\n",
            "Non-trainable params: 858,314\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3q4LFVGQTJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "class F1Metrics(Callback):\n",
        "\n",
        "    def __init__(self, id2label,sub_label,pad_value=0,validation_data=None):\n",
        "        super(F1Metrics, self).__init__()\n",
        "        self.id2label = id2label\n",
        "        self.sublabel = sub_label\n",
        "        self.validation_data = validation_data\n",
        "        self.is_fit = validation_data is None\n",
        "\n",
        "    def convert_idx_to_name(self, y):\n",
        "        y = [[self.id2label[i] for i in row] for row in y]\n",
        "        return y\n",
        "\n",
        "    def predict(self, X, y):\n",
        "        y_pred = self.model.predict_on_batch(X)\n",
        "        y_true = np.argmax(y, -1)\n",
        "        y_pred = np.argmax(y_pred, -1)\n",
        "        y_true = self.convert_idx_to_name(y_true)\n",
        "        y_pred = self.convert_idx_to_name(y_pred)\n",
        "        return y_true, y_pred\n",
        "\n",
        "    def score(self, y_true, y_pred):\n",
        "        score = flat_f1_score(y_true, y_pred,average='micro',labels=sub_label)\n",
        "        print(len(y_pred))\n",
        "        print(' - f1: %.2f' %(score))\n",
        "        return score\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if self.is_fit:\n",
        "            self.on_epoch_end_fit(epoch, logs)\n",
        "        else:\n",
        "            self.on_epoch_end_fit_generator(epoch, logs)\n",
        "\n",
        "    def on_epoch_end_fit(self, epoch, logs={}):\n",
        "        X = self.validation_data[0]\n",
        "        y = self.validation_data[1]\n",
        "        y_true, y_pred = self.predict(X, y)\n",
        "        score_val = self.score(y_true, y_pred)\n",
        "        logs['f1_val'] = score_val\n",
        "\n",
        "\n",
        "    def on_epoch_end_fit_generator(self, epoch, logs={}):\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        for X, y in self.validation_data:\n",
        "            y_true_batch, y_pred_batch = self.predict(X, y)\n",
        "            y_true.extend(y_true_batch)\n",
        "            y_pred.extend(y_pred_batch)\n",
        "        score = self.score(y_true, y_pred)\n",
        "        logs['f1'] = score\n",
        "\n",
        "f1score = F1Metrics(token_tag.index_word, sub_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjSNmgV3OyH6",
        "colab_type": "code",
        "outputId": "86a904a1-ae4a-4fb5-b6ec-b3a32752bb3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        }
      },
      "source": [
        "%%time\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "BATCH_SIZE = 200\n",
        "EPOCHS=20\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "history = model_2.fit([X_train, np.array(X_cas).reshape((len(X_cas), MAX_LEN))],\n",
        "                      np.array(Y_train),\n",
        "                      batch_size=BATCH_SIZE, \n",
        "                      epochs=EPOCHS, \n",
        "                      validation_split=0.2, \n",
        "                       #validation_data = (X_valid,np.array(Y_valid)),\n",
        "                      verbose=1,callbacks=[early_stopping])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 11232 samples, validate on 2809 samples\n",
            "Epoch 1/20\n",
            "11232/11232 [==============================] - 51s 5ms/step - loss: 40.6858 - crf_viterbi_accuracy: 0.8186 - val_loss: 35.3623 - val_crf_viterbi_accuracy: 0.9147\n",
            "Epoch 2/20\n",
            "11232/11232 [==============================] - 48s 4ms/step - loss: 40.1891 - crf_viterbi_accuracy: 0.9337 - val_loss: 35.2418 - val_crf_viterbi_accuracy: 0.9483\n",
            "Epoch 3/20\n",
            "11232/11232 [==============================] - 47s 4ms/step - loss: 40.1210 - crf_viterbi_accuracy: 0.9522 - val_loss: 35.2022 - val_crf_viterbi_accuracy: 0.9620\n",
            "Epoch 4/20\n",
            "11232/11232 [==============================] - 46s 4ms/step - loss: 40.0943 - crf_viterbi_accuracy: 0.9594 - val_loss: 35.1930 - val_crf_viterbi_accuracy: 0.9634\n",
            "Epoch 5/20\n",
            "11232/11232 [==============================] - 46s 4ms/step - loss: 40.0748 - crf_viterbi_accuracy: 0.9636 - val_loss: 35.1747 - val_crf_viterbi_accuracy: 0.9670\n",
            "Epoch 6/20\n",
            "11232/11232 [==============================] - 47s 4ms/step - loss: 40.0622 - crf_viterbi_accuracy: 0.9679 - val_loss: 35.1724 - val_crf_viterbi_accuracy: 0.9668\n",
            "Epoch 7/20\n",
            "11232/11232 [==============================] - 46s 4ms/step - loss: 40.0505 - crf_viterbi_accuracy: 0.9701 - val_loss: 35.1574 - val_crf_viterbi_accuracy: 0.9722\n",
            "Epoch 8/20\n",
            "11232/11232 [==============================] - 46s 4ms/step - loss: 40.0436 - crf_viterbi_accuracy: 0.9711 - val_loss: 35.1496 - val_crf_viterbi_accuracy: 0.9740\n",
            "Epoch 9/20\n",
            "11232/11232 [==============================] - 46s 4ms/step - loss: 40.0327 - crf_viterbi_accuracy: 0.9740 - val_loss: 35.1464 - val_crf_viterbi_accuracy: 0.9744\n",
            "Epoch 10/20\n",
            "11232/11232 [==============================] - 47s 4ms/step - loss: 40.0286 - crf_viterbi_accuracy: 0.9750 - val_loss: 35.1410 - val_crf_viterbi_accuracy: 0.9748\n",
            "Epoch 11/20\n",
            "11232/11232 [==============================] - 47s 4ms/step - loss: 40.0227 - crf_viterbi_accuracy: 0.9759 - val_loss: 35.1402 - val_crf_viterbi_accuracy: 0.9755\n",
            "Epoch 12/20\n",
            "11232/11232 [==============================] - 47s 4ms/step - loss: 40.0161 - crf_viterbi_accuracy: 0.9780 - val_loss: 35.1372 - val_crf_viterbi_accuracy: 0.9763\n",
            "Epoch 13/20\n",
            "11232/11232 [==============================] - 47s 4ms/step - loss: 40.0122 - crf_viterbi_accuracy: 0.9789 - val_loss: 35.1363 - val_crf_viterbi_accuracy: 0.9765\n",
            "Epoch 14/20\n",
            "11232/11232 [==============================] - 47s 4ms/step - loss: 40.0100 - crf_viterbi_accuracy: 0.9794 - val_loss: 35.1326 - val_crf_viterbi_accuracy: 0.9776\n",
            "Epoch 15/20\n",
            "11232/11232 [==============================] - 46s 4ms/step - loss: 40.0040 - crf_viterbi_accuracy: 0.9810 - val_loss: 35.1297 - val_crf_viterbi_accuracy: 0.9787\n",
            "Epoch 16/20\n",
            "11232/11232 [==============================] - 47s 4ms/step - loss: 40.0009 - crf_viterbi_accuracy: 0.9819 - val_loss: 35.1271 - val_crf_viterbi_accuracy: 0.9795\n",
            "Epoch 17/20\n",
            "11232/11232 [==============================] - 47s 4ms/step - loss: 39.9981 - crf_viterbi_accuracy: 0.9828 - val_loss: 35.1270 - val_crf_viterbi_accuracy: 0.9796\n",
            "Epoch 18/20\n",
            "11232/11232 [==============================] - 46s 4ms/step - loss: 39.9953 - crf_viterbi_accuracy: 0.9832 - val_loss: 35.1238 - val_crf_viterbi_accuracy: 0.9802\n",
            "Epoch 19/20\n",
            "11232/11232 [==============================] - 46s 4ms/step - loss: 39.9938 - crf_viterbi_accuracy: 0.9831 - val_loss: 35.1236 - val_crf_viterbi_accuracy: 0.9804\n",
            "Epoch 20/20\n",
            "11232/11232 [==============================] - 46s 4ms/step - loss: 39.9900 - crf_viterbi_accuracy: 0.9848 - val_loss: 35.1228 - val_crf_viterbi_accuracy: 0.9807\n",
            "CPU times: user 24min 11s, sys: 2min 24s, total: 26min 36s\n",
            "Wall time: 15min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOZlNNM-YcZv",
        "colab_type": "text"
      },
      "source": [
        "## Predict On Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEw08HSrSHG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2cbd4a96-eb69-4a5a-e52b-978e2e5c880e"
      },
      "source": [
        "%%time\n",
        "pred = model_2.predict([X_train, np.array(X_cas).reshape((len(X_cas), MAX_LEN))], verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14041/14041 [==============================] - 125s 9ms/step\n",
            "CPU times: user 3min 8s, sys: 26.5 s, total: 3min 34s\n",
            "Wall time: 2min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOlSUB8BShcQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "98a1f611-aee4-4dcf-d07e-a1d987780ab4"
      },
      "source": [
        "# TRain Eval\n",
        "preds = np.argmax(pred, axis=-1)\n",
        "y_tr_true = np.argmax(Y_train, -1)\n",
        "\n",
        "# Convert the index to tag\n",
        "pred_tag = [[token_tag.index_word[i] for i in row] for row in preds]\n",
        "y_tr_true_tag = [[token_tag.index_word[i] for i in row] for row in y_tr_true]\n",
        "\n",
        "report = flat_classification_report(y_pred=pred_tag, y_true=y_tr_true_tag,labels=sub_label)\n",
        "print(report)\n",
        "#F1 Score\n",
        "score=flat_f1_score(y_pred=pred_tag, y_true=y_tr_true_tag,average='micro',labels=sub_label)\n",
        "print(score)  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-PER       0.97      0.98      0.98     11128\n",
            "       I-ORG       0.95      0.91      0.93     10001\n",
            "       I-LOC       0.94      0.96      0.95      8286\n",
            "      I-MISC       0.88      0.89      0.89      4556\n",
            "      B-MISC       0.00      0.00      0.00        37\n",
            "       B-ORG       1.00      1.00      1.00        24\n",
            "       B-LOC       1.00      0.64      0.78        11\n",
            "\n",
            "   micro avg       0.95      0.94      0.94     34043\n",
            "   macro avg       0.82      0.77      0.79     34043\n",
            "weighted avg       0.95      0.94      0.94     34043\n",
            "\n",
            "0.9438248596726432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-xpkf6Dg7Zg",
        "colab_type": "text"
      },
      "source": [
        "## Predict On Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJsXpwO2flwh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "95318cb2-c5af-4af0-d1e3-0b4093293cfb"
      },
      "source": [
        "%%time\n",
        "X_cas_t = []\n",
        "for sentence in test_data:\n",
        "    sent_seq = []\n",
        "    for i in range(MAX_LEN):\n",
        "        word_seq = []\n",
        "        try:\n",
        "          word_seq.append(getCasing(sentence[i][0],case2Idx))\n",
        "        except:\n",
        "          word_seq.append(case2Idx.get('PADDING_TOKEN'))\n",
        "        sent_seq.append(word_seq)\n",
        "    X_cas_t.append(np.array(sent_seq))\n",
        "\n",
        "pred = model_2.predict([X_test, np.array(X_cas_t).reshape((len(X_cas_t), MAX_LEN))], verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3453/3453 [==============================] - 30s 9ms/step\n",
            "CPU times: user 45.7 s, sys: 6.56 s, total: 52.3 s\n",
            "Wall time: 30.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ8TiP-dhc35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "704cf0ff-97c3-4281-b010-e4624221e9e1"
      },
      "source": [
        "# Test Eval\n",
        "#pred_cat = model.predict(X_tr)\n",
        "preds = np.argmax(pred, axis=-1)\n",
        "y_tr_true = np.argmax(Y_test, -1)\n",
        "\n",
        "# Convert the index to tag\n",
        "pred_tag = [[token_tag.index_word[i] for i in row] for row in preds]\n",
        "y_tr_true_tag = [[token_tag.index_word[i] for i in row] for row in y_tr_true]\n",
        "                 \n",
        "                 \n",
        "report = flat_classification_report(y_pred=pred_tag, y_true=y_tr_true_tag, labels=sub_label)\n",
        "print(report)\n",
        "\n",
        "score=flat_f1_score(y_pred=pred_tag, y_true=y_tr_true_tag,average='micro', labels=sub_label)\n",
        "print(score)    "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-PER       0.95      0.92      0.93      2773\n",
            "       I-ORG       0.85      0.79      0.82      2491\n",
            "       I-LOC       0.86      0.88      0.87      1919\n",
            "      I-MISC       0.61      0.79      0.69       909\n",
            "      B-MISC       0.00      0.00      0.00         9\n",
            "       B-ORG       0.00      0.00      0.00         5\n",
            "       B-LOC       0.00      0.00      0.00         6\n",
            "\n",
            "   micro avg       0.85      0.85      0.85      8112\n",
            "   macro avg       0.47      0.48      0.47      8112\n",
            "weighted avg       0.86      0.85      0.85      8112\n",
            "\n",
            "0.8520862778836109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9VIWcmdQTOR",
        "colab_type": "text"
      },
      "source": [
        "## Underfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR4-YXy6O7C7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "# summarize history for accuracy\n",
        "plt.subplot(1,1,1)\n",
        "plt.plot(history.history['crf_viterbi_accuracy'])\n",
        "plt.plot(history.history['val_crf_viterbi_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='center right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE_zs6M7PhYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}