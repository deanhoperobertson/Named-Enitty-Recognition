{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM-CRF (SENNA 50D  + Features)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deanhoperobertson/Named-Enitty-Recognition/blob/master/BiLSTM-CRF%20(SENNA%2050D%20%2B%20Casing%20Features).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYs0s57M3jAf",
        "colab_type": "code",
        "outputId": "68a8cc0b-ccbb-4d9f-f920-ddd781d00e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "!sudo pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install sklearn_crfsuite\n",
        "!pip install keras==2.2.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-pp_161jc\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-pp_161jc\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.17.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=40f466bc00d650d43d39f95d276cdd02c8db4a55b9fdd2a57108390d7d2dffeb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9dudk_tu/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n",
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/86/cfcd71edca9d25d3d331209a20f6314b6f3f134c29478f90559cee9ce091/python_crfsuite-0.9.6-cp36-cp36m-manylinux1_x86_64.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.28.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.6 sklearn-crfsuite-0.3.6\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvLtrysY3xZn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "ff1211ff-0055-4359-dd57-9c9dcd3a2b12"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#keras and tensorflow packages\n",
        "from keras.layers.merge import add\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional,concatenate\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy\n",
        "from keras_contrib.metrics import crf_accuracy\n",
        "\n",
        "\n",
        "#evaluation\n",
        "from sklearn_crfsuite.metrics import flat_classification_report,flat_f1_score,flat_precision_score"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ5UL1PL39-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#github repo urls\n",
        "train_url = \"https://raw.githubusercontent.com/deanhoperobertson/Named-Enitty-Recognition/master/Data/train.txt\"\n",
        "test_url = \"https://raw.githubusercontent.com/deanhoperobertson/Named-Enitty-Recognition/master/Data/test.txt\"\n",
        "#valid_url = \"https://raw.githubusercontent.com/deanhoperobertson/Named-Enitty-Recognition/master/Data/valid.txt\"\n",
        "\n",
        "#import data\n",
        "train = urllib.request.urlopen(train_url).read()\n",
        "test = urllib.request.urlopen(test_url).read()\n",
        "#valid = urllib.request.urlopen(valid_url).read()\n",
        "\n",
        "train = train.decode('utf-8')\n",
        "test = test.decode('utf-8')\n",
        "#valid = valid.decode('utf-8')\n",
        "\n",
        "def readstring(filename, meth):\n",
        "    f = filename.split('\\n')\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for line in f:\n",
        "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
        "            if len(sentence) > 0:\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "            continue\n",
        "        splits = line.split(' ')\n",
        "        if meth.lower()==\"numbers1\":\n",
        "            sentence.append([hasNumbers1(splits[0]), splits[-1].strip()])\n",
        "        elif meth.lower()==\"numbers2\":\n",
        "            sentence.append([hasNumbers2(splits[0]), splits[-1].strip()])\n",
        "        else:\n",
        "            sentence.append([splits[0], splits[-1].strip()])\n",
        "    if len(sentence) > 0:\n",
        "        sentences.append(sentence)\n",
        "        sentence = []\n",
        "    return sentences\n",
        "\n",
        "def hasNumbers1(inputString):\n",
        "    if re.search(r'\\d', inputString):\n",
        "        return \"__\"\n",
        "    else:return(inputString)\n",
        "\n",
        "def hasNumbers2(text):\n",
        "  if text.isdigit():\n",
        "      return \"1\"\n",
        "  elif re.search(r'\\d',text) and re.search(r'\\,|\\.',text):\n",
        "      return \"1\" \n",
        "  else:\n",
        "      if re.search(r'\\d', text):\n",
        "          return(re.sub('\\d','D', text))\n",
        "      else:\n",
        "          return text\n",
        "\n",
        "#preproces the txt file\n",
        "train_data = readstring(train,\"Numbers1\")\n",
        "test_data = readstring(test,\"Numbers1\")\n",
        "#valid_data = readstring(valid,\"Numbers1\")\n",
        "\n",
        "#create corpus\n",
        "corpus = train_data.copy()\n",
        "corpus.extend(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQSami9V4FbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reformat_data(data,meth):\n",
        "  if meth.lower() == \"data\":\n",
        "    i=0\n",
        "  else: i=1\n",
        "  train = []\n",
        "  output= []\n",
        "  for sentence in data:\n",
        "    words=[]\n",
        "    for x in sentence:\n",
        "      words.append(x[i])\n",
        "    train.append(words)\n",
        "\n",
        "  for i in train:\n",
        "    string = ' '.join(i)\n",
        "    output.append(string)\n",
        "  return output\n",
        "\n",
        "def get_max_length(corpus):\n",
        "  length = []\n",
        "  for sentence in corpus:\n",
        "    length.append(len(sentence))\n",
        "  return int(max(length))\n",
        "\n",
        "def number_of_tags(corpus):\n",
        "  tags=[]\n",
        "  for sentence in corpus:\n",
        "    for tag in sentence:\n",
        "      tags.append(tag[1])\n",
        "  return int(len(list(set(tags))))\n",
        "\n",
        "\n",
        "MAX_LEN = get_max_length(corpus)\n",
        "N_tags = number_of_tags(corpus)\n",
        "\n",
        "train = reformat_data(train_data,\"data\")\n",
        "test = reformat_data(test_data,\"data\")\n",
        "#valid = reformat_data(valid_data,\"data\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOyKFaZ64Piy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a tokenizer\n",
        "token_word = text.Tokenizer(char_level=False, lower=True, filters=\"}\", oov_token='UNK')\n",
        "token_word.fit_on_texts(train)\n",
        "\n",
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "X_train = sequence.pad_sequences(token_word.texts_to_sequences(train), maxlen=MAX_LEN,padding=\"post\")\n",
        "X_test = sequence.pad_sequences(token_word.texts_to_sequences(test), maxlen=MAX_LEN,padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "791RIPxLFdE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = reformat_data(train_data,\"tags\")\n",
        "test = reformat_data(test_data,\"tags\")\n",
        "\n",
        "# create a tokenizer\n",
        "token_tag = text.Tokenizer(char_level=False, lower=False, filters=\"}\")\n",
        "token_tag.fit_on_texts(train)\n",
        "\n",
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "Y = sequence.pad_sequences(token_tag.texts_to_sequences(train), maxlen=MAX_LEN,padding=\"post\")\n",
        "# One-Hot encode categorical labels\n",
        "Y_train = [to_categorical(i, num_classes=N_tags+1) for i in Y]\n",
        "\n",
        "Y = sequence.pad_sequences(token_tag.texts_to_sequences(test), maxlen=MAX_LEN,padding=\"post\")\n",
        "# One-Hot encode categorical labels\n",
        "Y_test = [to_categorical(i, num_classes=N_tags+1) for i in Y]\n",
        "\n",
        "#add padding \n",
        "token_tag.index_word[0]=\"PAD\"\n",
        "sub_label = list(token_tag.index_word.values())\n",
        "sub_label.remove('O')\n",
        "sub_label.remove('PAD')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADOS66iMHYkr",
        "colab_type": "code",
        "outputId": "57dae008-72b9-4697-95db-59836372c865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDX21YJbJy6N",
        "colab_type": "code",
        "outputId": "5f0029e2-944d-4738-cad7-1c1575f6f7f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "root_path = \"/content/drive/My Drive/SENNA.txt\"\n",
        "embeddings_index={}\n",
        "f = open(root_path, encoding = \"utf-8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 130000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OM5O7xy-h3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create emedding matrix\n",
        "EMBEDDING=50\n",
        "word_index = token_word.word_index\n",
        "embedding_matrix = np.zeros((len(token_word.word_index) + 1, EMBEDDING))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all-zeros.\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHwzSe4s8cj",
        "colab_type": "code",
        "outputId": "1aaabe31-8cbb-4a99-b0a9-0485704b7e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "checks=[]\n",
        "words=[]\n",
        "for i in range(0,len(token_word.word_index)+1):\n",
        "  if embedding_matrix[i][0] == 0.0:\n",
        "    checks.append(1)\n",
        "    words.append(list(token_word.word_index.items())[i-1][0])\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "print(\"Missing words from Embeddings: %d (%.2f%%)\" %(len(checks),(len(checks)/len(token_word.word_index)*100)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Missing words from Embeddings: 1554 (9.05%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0G18EdzTSqI",
        "colab_type": "text"
      },
      "source": [
        "## Create Casing Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b0O3b-HTRfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getCasing(word, caseLookup):   \n",
        "    casing = 'other'\n",
        "    \n",
        "    numDigits = 0\n",
        "    for char in word:\n",
        "        if char.isdigit():\n",
        "            numDigits += 1\n",
        "            \n",
        "    digitFraction = numDigits / float(len(word))\n",
        "    \n",
        "    if word.isdigit(): #Is a digit\n",
        "        casing = 'numeric'\n",
        "    elif digitFraction > 0.5:\n",
        "        casing = 'mainly_numeric'\n",
        "    elif word.islower(): #All lower case\n",
        "        casing = 'allLower'\n",
        "    elif word.isupper(): #All upper case\n",
        "        casing = 'allUpper'\n",
        "    elif word[0].isupper(): #is a title, initial char upper, then all lower\n",
        "        casing = 'initialUpper'\n",
        "    elif numDigits > 0:\n",
        "        casing = 'contains_digit'  \n",
        "    return caseLookup[casing]\n",
        "\n",
        "case2Idx = {'numeric': 7, 'allLower':1, 'allUpper':2, 'initialUpper':3, 'other':4, \n",
        "            'mainly_numeric':5, 'contains_digit': 6, 'PADDING_TOKEN':0}\n",
        "\n",
        "caseEmbeddings = np.identity(len(case2Idx), dtype='float32')\n",
        "\n",
        "\n",
        "X_cas = []\n",
        "for sentence in train_data:\n",
        "    sent_seq = []\n",
        "    for i in range(MAX_LEN):\n",
        "        word_seq = []\n",
        "        try:\n",
        "          word_seq.append(getCasing(sentence[i][0],case2Idx))\n",
        "        except:\n",
        "          word_seq.append(case2Idx.get('PADDING_TOKEN'))\n",
        "        sent_seq.append(word_seq)\n",
        "    X_cas.append(np.array(sent_seq))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLUxQqI8Md4N",
        "colab_type": "text"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJXcEXJYMg4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "108e7ce4-31dd-4290-9a20-129724276b9a"
      },
      "source": [
        "# Model definition\n",
        "\n",
        "words_in = Input(shape=(MAX_LEN,), name=\"Input_Words\")\n",
        "casing_in = Input(shape=(MAX_LEN,), name=\"Input_Casings\")\n",
        "\n",
        "word_emb = Embedding(input_dim=len(token_word.word_index) + 1,output_dim=EMBEDDING,\n",
        "                     weights=[embedding_matrix],input_length=MAX_LEN,\n",
        "                     trainable=False,mask_zero=True)(words_in)\n",
        "\n",
        "# casing_emb = TimeDistributed(Embedding(input_dim=caseEmbeddings.shape[0],output_dim=caseEmbeddings.shape[1],\n",
        "#                        weights=[caseEmbeddings], trainable=False, mask_zero=True))(casing_in)\n",
        "\n",
        "casing_emb = Embedding(input_dim=caseEmbeddings.shape[0],output_dim=caseEmbeddings.shape[1],\n",
        "                       weights=[caseEmbeddings], trainable=False, mask_zero=True)(casing_in)\n",
        "\n",
        "# character LSTM to get word encodings by characters\n",
        "# cas_enc = TimeDistributed(LSTM(units=20, return_sequences=False, #20\n",
        "#                                 recurrent_dropout=0.5))(casing_emb) #0.3/0.5\n",
        "\n",
        "model_2 = concatenate([word_emb,casing_emb])\n",
        "model_2 = Bidirectional(LSTM(units=300, return_sequences=True,\n",
        "                           recurrent_dropout=0.1, dropout=0.3))(model_2) \n",
        "\n",
        "model_2 = TimeDistributed(Dense(50, activation=\"relu\"))(model_2)\n",
        "crf = CRF(N_tags+1)  # CRF layer\n",
        "out = crf(model_2)  # output\n",
        "model_2 = Model([words_in, casing_in], out)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA9_8iSPMiyn",
        "colab_type": "code",
        "outputId": "abc564ff-2fcc-44a5-c7bf-6bfc121d72fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "from keras import optimizers\n",
        "#adam=optimizers.Adam(clipvalue=0.5)\n",
        "adam=optimizers.Adam(clipnorm=1.0)\n",
        "\n",
        "model_2.compile(optimizer=adam, loss=crf_loss,metrics=[crf_viterbi_accuracy])\n",
        "model_2.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input_Words (InputLayer)        (None, 124)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input_Casings (InputLayer)      (None, 124)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 124, 50)      858250      Input_Words[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 124, 8)       64          Input_Casings[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 124, 58)      0           embedding_1[0][0]                \n",
            "                                                                 embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 124, 600)     861600      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 124, 50)      30050       bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "crf_1 (CRF)                     (None, 124, 9)       558         time_distributed_1[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 1,750,522\n",
            "Trainable params: 892,208\n",
            "Non-trainable params: 858,314\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3q4LFVGQTJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "class F1Metrics(Callback):\n",
        "\n",
        "    def __init__(self, id2label,sub_label,pad_value=0,validation_data=None):\n",
        "        super(F1Metrics, self).__init__()\n",
        "        self.id2label = id2label\n",
        "        self.sublabel = sub_label\n",
        "        self.validation_data = validation_data\n",
        "        self.is_fit = validation_data is None\n",
        "\n",
        "    def convert_idx_to_name(self, y):\n",
        "        y = [[self.id2label[i] for i in row] for row in y]\n",
        "        return y\n",
        "\n",
        "    def predict(self, X, y):\n",
        "        y_pred = self.model.predict_on_batch(X)\n",
        "        y_true = np.argmax(y, -1)\n",
        "        y_pred = np.argmax(y_pred, -1)\n",
        "        y_true = self.convert_idx_to_name(y_true)\n",
        "        y_pred = self.convert_idx_to_name(y_pred)\n",
        "        return y_true, y_pred\n",
        "\n",
        "    def score(self, y_true, y_pred):\n",
        "        score = flat_f1_score(y_true, y_pred,average='micro',labels=sub_label)\n",
        "        print(len(y_pred))\n",
        "        print(' - f1: %.2f' %(score))\n",
        "        return score\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if self.is_fit:\n",
        "            self.on_epoch_end_fit(epoch, logs)\n",
        "        else:\n",
        "            self.on_epoch_end_fit_generator(epoch, logs)\n",
        "\n",
        "    def on_epoch_end_fit(self, epoch, logs={}):\n",
        "        X = self.validation_data[0]\n",
        "        y = self.validation_data[1]\n",
        "        y_true, y_pred = self.predict(X, y)\n",
        "        score_val = self.score(y_true, y_pred)\n",
        "        logs['f1_val'] = score_val\n",
        "\n",
        "\n",
        "    def on_epoch_end_fit_generator(self, epoch, logs={}):\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        for X, y in self.validation_data:\n",
        "            y_true_batch, y_pred_batch = self.predict(X, y)\n",
        "            y_true.extend(y_true_batch)\n",
        "            y_pred.extend(y_pred_batch)\n",
        "        score = self.score(y_true, y_pred)\n",
        "        logs['f1'] = score\n",
        "\n",
        "f1score = F1Metrics(token_tag.index_word, sub_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjSNmgV3OyH6",
        "colab_type": "code",
        "outputId": "8d81d728-f516-4c48-a7c8-f4b74a7a57c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "%%time\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import Callback\n",
        "BATCH_SIZE = 200\n",
        "EPOCHS=20\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "history = model_2.fit([X_train, np.array(X_cas).reshape((len(X_cas), MAX_LEN))],\n",
        "                      np.array(Y_train),\n",
        "                      batch_size=BATCH_SIZE, \n",
        "                      epochs=EPOCHS, \n",
        "                      validation_split=0.2, \n",
        "                       #validation_data = (X_valid,np.array(Y_valid)),\n",
        "                      verbose=1,callbacks=[early_stopping])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 11232 samples, validate on 2809 samples\n",
            "Epoch 1/20\n",
            "11232/11232 [==============================] - 66s 6ms/step - loss: 40.6626 - crf_viterbi_accuracy: 0.8279 - val_loss: 35.2840 - val_crf_viterbi_accuracy: 0.9344\n",
            "Epoch 2/20\n",
            "11232/11232 [==============================] - 60s 5ms/step - loss: 40.1491 - crf_viterbi_accuracy: 0.9445 - val_loss: 35.2077 - val_crf_viterbi_accuracy: 0.9565\n",
            "Epoch 3/20\n",
            "11232/11232 [==============================] - 60s 5ms/step - loss: 40.0988 - crf_viterbi_accuracy: 0.9567 - val_loss: 35.1819 - val_crf_viterbi_accuracy: 0.9638\n",
            "Epoch 4/20\n",
            "11232/11232 [==============================] - 61s 5ms/step - loss: 40.0744 - crf_viterbi_accuracy: 0.9626 - val_loss: 35.1656 - val_crf_viterbi_accuracy: 0.9687\n",
            "Epoch 5/20\n",
            "11232/11232 [==============================] - 61s 5ms/step - loss: 40.0555 - crf_viterbi_accuracy: 0.9675 - val_loss: 35.1554 - val_crf_viterbi_accuracy: 0.9723\n",
            "Epoch 6/20\n",
            "11232/11232 [==============================] - 61s 5ms/step - loss: 40.0427 - crf_viterbi_accuracy: 0.9705 - val_loss: 35.1530 - val_crf_viterbi_accuracy: 0.9719\n",
            "Epoch 7/20\n",
            "11232/11232 [==============================] - 60s 5ms/step - loss: 40.0319 - crf_viterbi_accuracy: 0.9726 - val_loss: 35.1467 - val_crf_viterbi_accuracy: 0.9747\n",
            "Epoch 8/20\n",
            "11232/11232 [==============================] - 61s 5ms/step - loss: 40.0225 - crf_viterbi_accuracy: 0.9755 - val_loss: 35.1400 - val_crf_viterbi_accuracy: 0.9767\n",
            "Epoch 9/20\n",
            "11232/11232 [==============================] - 61s 5ms/step - loss: 40.0135 - crf_viterbi_accuracy: 0.9782 - val_loss: 35.1379 - val_crf_viterbi_accuracy: 0.9769\n",
            "Epoch 10/20\n",
            "11232/11232 [==============================] - 61s 5ms/step - loss: 40.0100 - crf_viterbi_accuracy: 0.9789 - val_loss: 35.1342 - val_crf_viterbi_accuracy: 0.9788\n",
            "Epoch 11/20\n",
            "11232/11232 [==============================] - 61s 5ms/step - loss: 40.0033 - crf_viterbi_accuracy: 0.9806 - val_loss: 35.1386 - val_crf_viterbi_accuracy: 0.9784\n",
            "Epoch 12/20\n",
            "11232/11232 [==============================] - 60s 5ms/step - loss: 39.9978 - crf_viterbi_accuracy: 0.9822 - val_loss: 35.1302 - val_crf_viterbi_accuracy: 0.9803\n",
            "Epoch 13/20\n",
            "11232/11232 [==============================] - 61s 5ms/step - loss: 39.9938 - crf_viterbi_accuracy: 0.9831 - val_loss: 35.1307 - val_crf_viterbi_accuracy: 0.9807\n",
            "Epoch 14/20\n",
            "11232/11232 [==============================] - 61s 5ms/step - loss: 39.9908 - crf_viterbi_accuracy: 0.9838 - val_loss: 35.1301 - val_crf_viterbi_accuracy: 0.9802\n",
            "Epoch 15/20\n",
            "11232/11232 [==============================] - 61s 5ms/step - loss: 39.9872 - crf_viterbi_accuracy: 0.9850 - val_loss: 35.1287 - val_crf_viterbi_accuracy: 0.9814\n",
            "Epoch 16/20\n",
            "11232/11232 [==============================] - 60s 5ms/step - loss: 39.9846 - crf_viterbi_accuracy: 0.9860 - val_loss: 35.1306 - val_crf_viterbi_accuracy: 0.9808\n",
            "Epoch 17/20\n",
            "11232/11232 [==============================] - 61s 5ms/step - loss: 39.9839 - crf_viterbi_accuracy: 0.9856 - val_loss: 35.1318 - val_crf_viterbi_accuracy: 0.9804\n",
            "CPU times: user 27min 9s, sys: 2min 56s, total: 30min 6s\n",
            "Wall time: 17min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOZlNNM-YcZv",
        "colab_type": "text"
      },
      "source": [
        "## Predict On Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEw08HSrSHG2",
        "colab_type": "code",
        "outputId": "380e2900-727b-497f-ddfa-c93b274f012b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "pred = model_2.predict([X_train, np.array(X_cas).reshape((len(X_cas), MAX_LEN))], verbose=1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14041/14041 [==============================] - 170s 12ms/step\n",
            "CPU times: user 4min 21s, sys: 38.6 s, total: 5min\n",
            "Wall time: 2min 50s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOlSUB8BShcQ",
        "colab_type": "code",
        "outputId": "3604ce2b-b539-4412-e99b-ecb0668fec57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# TRain Eval\n",
        "preds = np.argmax(pred, axis=-1)\n",
        "y_tr_true = np.argmax(Y_train, -1)\n",
        "\n",
        "# Convert the index to tag\n",
        "pred_tag = [[token_tag.index_word[i] for i in row] for row in preds]\n",
        "y_tr_true_tag = [[token_tag.index_word[i] for i in row] for row in y_tr_true]\n",
        "\n",
        "report = flat_classification_report(y_pred=pred_tag, y_true=y_tr_true_tag,labels=sub_label)\n",
        "print(report)\n",
        "#F1 Score\n",
        "score=flat_f1_score(y_pred=pred_tag, y_true=y_tr_true_tag,average='micro',labels=sub_label)\n",
        "print(score)  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-PER       0.97      0.99      0.98     11128\n",
            "       I-ORG       0.89      0.96      0.92     10001\n",
            "       I-LOC       0.97      0.94      0.95      8286\n",
            "      I-MISC       0.94      0.85      0.89      4556\n",
            "      B-MISC       0.83      0.14      0.23        37\n",
            "       B-ORG       1.00      1.00      1.00        24\n",
            "       B-LOC       1.00      0.73      0.84        11\n",
            "\n",
            "   micro avg       0.94      0.95      0.94     34043\n",
            "   macro avg       0.94      0.80      0.83     34043\n",
            "weighted avg       0.94      0.95      0.94     34043\n",
            "\n",
            "0.9441208324795832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-xpkf6Dg7Zg",
        "colab_type": "text"
      },
      "source": [
        "## Predict On Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJsXpwO2flwh",
        "colab_type": "code",
        "outputId": "c84e8b4b-0bf9-4a53-f6d7-634097014996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "X_cas_t = []\n",
        "for sentence in test_data:\n",
        "    sent_seq = []\n",
        "    for i in range(MAX_LEN):\n",
        "        word_seq = []\n",
        "        try:\n",
        "          word_seq.append(getCasing(sentence[i][0],case2Idx))\n",
        "        except:\n",
        "          word_seq.append(case2Idx.get('PADDING_TOKEN'))\n",
        "        sent_seq.append(word_seq)\n",
        "    X_cas_t.append(np.array(sent_seq))\n",
        "\n",
        "pred = model_2.predict([X_test, np.array(X_cas_t).reshape((len(X_cas_t), MAX_LEN))], verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3453/3453 [==============================] - 42s 12ms/step\n",
            "CPU times: user 1min 4s, sys: 9.63 s, total: 1min 14s\n",
            "Wall time: 42 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ8TiP-dhc35",
        "colab_type": "code",
        "outputId": "b003e088-0e52-405d-e4fc-02abf82159df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# Test Eval\n",
        "#pred_cat = model.predict(X_tr)\n",
        "preds = np.argmax(pred, axis=-1)\n",
        "y_tr_true = np.argmax(Y_test, -1)\n",
        "\n",
        "# Convert the index to tag\n",
        "pred_tag = [[token_tag.index_word[i] for i in row] for row in preds]\n",
        "y_tr_true_tag = [[token_tag.index_word[i] for i in row] for row in y_tr_true]\n",
        "                 \n",
        "                 \n",
        "report = flat_classification_report(y_pred=pred_tag, y_true=y_tr_true_tag, labels=sub_label)\n",
        "print(report)\n",
        "\n",
        "score=flat_f1_score(y_pred=pred_tag, y_true=y_tr_true_tag,average='micro', labels=sub_label)\n",
        "print(score)    "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-PER       0.91      0.95      0.93      2773\n",
            "       I-ORG       0.78      0.84      0.81      2491\n",
            "       I-LOC       0.90      0.84      0.87      1919\n",
            "      I-MISC       0.73      0.75      0.74       909\n",
            "      B-MISC       0.00      0.00      0.00         9\n",
            "       B-ORG       0.00      0.00      0.00         5\n",
            "       B-LOC       0.00      0.00      0.00         6\n",
            "\n",
            "   micro avg       0.84      0.86      0.85      8112\n",
            "   macro avg       0.47      0.48      0.48      8112\n",
            "weighted avg       0.84      0.86      0.85      8112\n",
            "\n",
            "0.8535768645357686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9VIWcmdQTOR",
        "colab_type": "text"
      },
      "source": [
        "## Underfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR4-YXy6O7C7",
        "colab_type": "code",
        "outputId": "d50de7b5-9779-45f8-801e-8e864a317fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "# summarize history for accuracy\n",
        "plt.subplot(1,1,1)\n",
        "plt.plot(history.history['crf_viterbi_accuracy'])\n",
        "plt.plot(history.history['val_crf_viterbi_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='center right')\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ24AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwW9mljMOfjOznHHwm5nlzP8H05i+3qBOd9sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE_zs6M7PhYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}