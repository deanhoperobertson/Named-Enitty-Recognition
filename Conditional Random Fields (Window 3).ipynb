{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Random Field Model (Window 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Custom models\n",
    "from prepro import readfile, get_sentence, is_number, extract_words,get_label,partial_tags\n",
    "\n",
    "#Model\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "#Evalulation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn_crfsuite.metrics import flat_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from my github repo\n",
    "test = readfile(\"test.txt\")\n",
    "train =readfile(\"train.txt\")\n",
    "\n",
    "# filenames = ['train.txt', 'valid.txt']\n",
    "# with open('Combined.txt', 'w') as outfile:\n",
    "#     for fname in filenames:\n",
    "#         with open(fname) as infile:\n",
    "#             for line in infile:\n",
    "#                 outfile.write(line)\n",
    "                \n",
    "# train =readfile(\"Combined.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthographic Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special Features:\n",
    "def count_vowel(word):\n",
    "    '''\n",
    "    Function returns the number of vowels in token\n",
    "    '''\n",
    "    return sum(list(map(word.lower().count, \"aeiou\")))\n",
    "\n",
    "def dash(word):\n",
    "    '''\n",
    "    The Function returns whether or not the token contains a dash\n",
    "    '''\n",
    "    return 1 if \"-\" in word else 0\n",
    "\n",
    "def count_consonants(word):\n",
    "    '''\n",
    "    The Function returns the number of consonants in a token\n",
    "    '''\n",
    "    vowels=\"aeiou\"\n",
    "    return sum(i not in vowels for i in word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sentence,i):\n",
    "    word = sentence[i]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'Prefix_2': word[:2],\n",
    "        'Prefix_3': word[:3], \n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.islower()': word.islower(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.isalpha()': word.isalpha(),\n",
    "        'word.isalnum()': word.isalnum(), \n",
    "        \"vowels\": count_vowel(word),\n",
    "        \"dash\": dash(word),\n",
    "        \"consonants\": count_consonants(word),\n",
    "        'Suffix_2': word[-2:],\n",
    "        'Suffix_3': word[-3:],\n",
    "        \n",
    "    }\n",
    "    if  i == 1 :\n",
    "        '''\n",
    "        Get the token before in the sentence\n",
    "        '''\n",
    "        word1 = sentence[i-1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word Prefix_2': word1[:2],\n",
    "            '-1:word Prefix_3': word1[:3], \n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.islower()': word1.lower(),\n",
    "            '-1:word.isdigit()': word1.isdigit(),\n",
    "            '-1:word.isalpha()': word1.isalpha(),\n",
    "            '-1:word.isalnum()': word1.isalnum(), \n",
    "            \"-1:word.vowels\": count_vowel(word1),\n",
    "            \"-1:word.dash\": dash(word1),\n",
    "            \"-1:word.consonants\": count_consonants(word1),\n",
    "            '-1:word.Suffix_2': word1[-2:],\n",
    "            '-1:word.Suffix_3': word1[-3:],\n",
    "        })\n",
    "        \n",
    "    elif i==2:\n",
    "        word1 = sentence[i-1]\n",
    "        word2 = sentence[i-2]\n",
    "        \n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word Prefix_2': word1[:2],\n",
    "            '-1:word Prefix_3': word1[:3], \n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.islower()': word1.lower(),\n",
    "            '-1:word.isdigit()': word1.isdigit(),\n",
    "            '-1:word.isalpha()': word1.isalpha(),\n",
    "            '-1:word.isalnum()': word1.isalnum(), \n",
    "            \"-1:word.vowels\": count_vowel(word1),\n",
    "            \"-1:word.dash\": dash(word1),\n",
    "            \"-1:word.consonants\": count_consonants(word1),\n",
    "            '-1:word.Suffix_2': word1[-2:],\n",
    "            '-1:word.Suffix_3': word1[-3:],\n",
    "            \n",
    "            '-2:word.lower()': word2.lower(),\n",
    "            '-2:word Prefix_2': word2[:2],\n",
    "            '-2:word Prefix_3': word2[:3], \n",
    "            '-2:word.istitle()': word2.istitle(),\n",
    "            '-2:word.isupper()': word2.isupper(),\n",
    "            '-2:word.islower()': word2.lower(),\n",
    "            '-2:word.isdigit()': word2.isdigit(),\n",
    "            '-2:word.isalpha()': word2.isalpha(),\n",
    "            '-2:word.isalnum()': word2.isalnum(), \n",
    "            \"-2:word.vowels\": count_vowel(word2),\n",
    "            \"-2:word.dash\": dash(word2),\n",
    "            \"-2:word.consonants\": count_consonants(word2),\n",
    "            '-2:word.Suffix_2': word2[-2:],\n",
    "            '-2:word.Suffix_3': word2[-3:],\n",
    "        })\n",
    "        \n",
    "    elif i>2:\n",
    "        word1 = sentence[i-1]\n",
    "        word2 = sentence[i-2]\n",
    "        word3 = sentence[i-3]\n",
    "        \n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word Prefix_2': word1[:2],\n",
    "            '-1:word Prefix_3': word1[:3], \n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.islower()': word1.lower(),\n",
    "            '-1:word.isdigit()': word1.isdigit(),\n",
    "            '-1:word.isalpha()': word1.isalpha(),\n",
    "            '-1:word.isalnum()': word1.isalnum(), \n",
    "            \"-1:word.vowels\": count_vowel(word1),\n",
    "            \"-1:word.dash\": dash(word1),\n",
    "            \"-1:word.consonants\": count_consonants(word1),\n",
    "            '-1:word.Suffix_2': word1[-2:],\n",
    "            '-1:word.Suffix_3': word1[-3:],\n",
    "            \n",
    "            '-2:word.lower()': word2.lower(),\n",
    "            '-2:word Prefix_2': word2[:2],\n",
    "            '-2:word Prefix_3': word2[:3], \n",
    "            '-2:word.istitle()': word2.istitle(),\n",
    "            '-2:word.isupper()': word2.isupper(),\n",
    "            '-2:word.islower()': word2.lower(),\n",
    "            '-2:word.isdigit()': word2.isdigit(),\n",
    "            '-2:word.isalpha()': word2.isalpha(),\n",
    "            '-2:word.isalnum()': word2.isalnum(), \n",
    "            \"-2:word.vowels\": count_vowel(word2),\n",
    "            \"-2:word.dash\": dash(word2),\n",
    "            \"-2:word.consonants\": count_consonants(word2),\n",
    "            '-2:word.Suffix_2': word2[-2:],\n",
    "            '-2:word.Suffix_3': word2[-3:],\n",
    "            \n",
    "            '-3:word.lower()': word3.lower(),\n",
    "            '-3:word Prefix_2': word3[:2],\n",
    "            '-3:word Prefix_3': word3[:3], \n",
    "            '-3:word.istitle()': word3.istitle(),\n",
    "            '-3:word.isupper()': word3.isupper(),\n",
    "            '-3:word.islower()': word3.lower(),\n",
    "            '-3:word.isdigit()': word3.isdigit(),\n",
    "            '-3:word.isalpha()': word3.isalpha(),\n",
    "            '-3:word.isalnum()': word3.isalnum(), \n",
    "            \"-3:word.vowels\": count_vowel(word3),\n",
    "            \"-3:word.dash\": dash(word3),\n",
    "            \"-3:word.consonants\": count_consonants(word3),\n",
    "            '-3:word.Suffix_2': word3[-2:],\n",
    "            '-3:word.Suffix_3': word3[-3:],\n",
    "        })\n",
    "        \n",
    "    else:\n",
    "        features['Start'] = True\n",
    "        \n",
    "    if i == len(sentence)-2:\n",
    "        '''\n",
    "        Get the token after in the sentence\n",
    "        '''\n",
    "        word1 = sentence[i+1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.Prefix_2': word1[:2],\n",
    "            '+1:word.Prefix_3': word1[:3], \n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.islower()': word1.lower(),\n",
    "            '+1:word.isdigit()': word1.isdigit(),\n",
    "            '+1:word.isalpha()': word1.isalpha(),\n",
    "            '+1:word.isalnum()': word1.isalnum(), \n",
    "            \"+1:word.vowels\": count_vowel(word1),\n",
    "            \"+1:word.dash\": dash(word1),\n",
    "            \"+1:word.consonants\": count_consonants(word1),\n",
    "            '+1:word.Suffix_2': word1[-2:],\n",
    "            '+1:word.Suffix_3': word1[-3:],\n",
    "        })\n",
    "        \n",
    "    elif i == len(sentence)-3:\n",
    "        word1 = sentence[i+1]\n",
    "        word2 = sentence[i+2]\n",
    "        \n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.Prefix_2': word1[:2],\n",
    "            '+1:word.Prefix_3': word1[:3], \n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.islower()': word1.lower(),\n",
    "            '+1:word.isdigit()': word1.isdigit(),\n",
    "            '+1:word.isalpha()': word1.isalpha(),\n",
    "            '+1:word.isalnum()': word1.isalnum(), \n",
    "            \"+1:word.vowels\": count_vowel(word1),\n",
    "            \"+1:word.dash\": dash(word1),\n",
    "            \"+1:word.consonants\": count_consonants(word1),\n",
    "            '+1:word.Suffix_2': word1[-2:],\n",
    "            '+1:word.Suffix_3': word1[-3:],\n",
    "            \n",
    "            '+2:word.lower()': word2.lower(),\n",
    "            '+2:word.Prefix_2': word2[:2],\n",
    "            '+2:word.Prefix_3': word2[:3], \n",
    "            '+2:word.istitle()': word2.istitle(),\n",
    "            '+2:word.isupper()': word2.isupper(),\n",
    "            '+2:word.islower()': word2.lower(),\n",
    "            '+2:word.isdigit()': word2.isdigit(),\n",
    "            '+2:word.isalpha()': word2.isalpha(),\n",
    "            '+2:word.isalnum()': word2.isalnum(), \n",
    "            \"+2:word.vowels\": count_vowel(word2),\n",
    "            \"+2:word.dash\": dash(word2),\n",
    "            \"+2:word.consonants\": count_consonants(word2),\n",
    "            '+2:word.Suffix_2': word2[-2:],\n",
    "            '+2:word.Suffix_3': word2[-3:],\n",
    "        })\n",
    "        \n",
    "    elif i < len(sentence)-3:\n",
    "        word1 = sentence[i+1]\n",
    "        word2 = sentence[i+2]\n",
    "        word3 = sentence[i+3]\n",
    "        \n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.Prefix_2': word1[:2],\n",
    "            '+1:word.Prefix_3': word1[:3], \n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.islower()': word1.lower(),\n",
    "            '+1:word.isdigit()': word1.isdigit(),\n",
    "            '+1:word.isalpha()': word1.isalpha(),\n",
    "            '+1:word.isalnum()': word1.isalnum(), \n",
    "            \"+1:word.vowels\": count_vowel(word1),\n",
    "            \"+1:word.dash\": dash(word1),\n",
    "            \"+1:word.consonants\": count_consonants(word1),\n",
    "            '+1:word.Suffix_2': word1[-2:],\n",
    "            '+1:word.Suffix_3': word1[-3:],\n",
    "            \n",
    "            '+2:word.lower()': word2.lower(),\n",
    "            '+2:word.Prefix_2': word2[:2],\n",
    "            '+2:word.Prefix_3': word2[:3], \n",
    "            '+2:word.istitle()': word2.istitle(),\n",
    "            '+2:word.isupper()': word2.isupper(),\n",
    "            '+2:word.islower()': word2.lower(),\n",
    "            '+2:word.isdigit()': word2.isdigit(),\n",
    "            '+2:word.isalpha()': word2.isalpha(),\n",
    "            '+2:word.isalnum()': word2.isalnum(), \n",
    "            \"+2:word.vowels\": count_vowel(word2),\n",
    "            \"+2:word.dash\": dash(word2),\n",
    "            \"+2:word.consonants\": count_consonants(word2),\n",
    "            '+2:word.Suffix_2': word2[-2:],\n",
    "            '+2:word.Suffix_3': word2[-3:],\n",
    "            \n",
    "            '+3:word.lower()': word3.lower(),\n",
    "            '+3:word.Prefix_2': word3[:2],\n",
    "            '+3:word.Prefix_3': word3[:3], \n",
    "            '+3:word.istitle()': word3.istitle(),\n",
    "            '+3:word.isupper()': word3.isupper(),\n",
    "            '+3:word.islower()': word3.lower(),\n",
    "            '+3:word.isdigit()': word3.isdigit(),\n",
    "            '+3:word.isalpha()': word3.isalpha(),\n",
    "            '+3:word.isalnum()': word3.isalnum(), \n",
    "            \"+3:word.vowels\": count_vowel(word3),\n",
    "            \"+3:word.dash\": dash(word3),\n",
    "            \"+3:word.consonants\": count_consonants(word3),\n",
    "            '+3:word.Suffix_2': word3[-2:],\n",
    "            '+3:word.Suffix_3': word3[-3:],\n",
    "        })\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        features['End'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def get_all_sentences(dataset):\n",
    "    sentences=[]\n",
    "    for i in range(len(dataset)):\n",
    "        sentences.append(get_sentence(dataset,i+1))\n",
    "    return sentences\n",
    "\n",
    "def get_all_labels(dataset):\n",
    "    labels=[]\n",
    "    for i in range(len(dataset)):\n",
    "        #labels.append(partial_tags(get_label(dataset,i+1)))\n",
    "        labels.append(get_label(dataset,i+1))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "#get the first sentence\n",
    "sent = get_sentence(train,1)\n",
    "#label = partial_tags(get_label(train,1))\n",
    "label = get_label(train,1)\n",
    "\n",
    "#print out first sentence\n",
    "print(sent)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applt feature engineering\n",
    "train_sents = get_all_sentences(train)\n",
    "train_labels = get_all_labels(train)\n",
    "test_sents = get_all_sentences(test)\n",
    "test_labels = get_all_labels(test)\n",
    "\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = train_labels\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = test_labels\n",
    "\n",
    "\n",
    "sub_labels=list(set([item for sublist in train_labels for item in sublist]))\n",
    "sub_labels.remove(\"O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Condtional Random Field Model\n",
    "\n",
    "### Model 1\n",
    "- Using Stochastic Gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      I-MISC       0.98      0.96      0.97      4556\n",
      "      B-MISC       1.00      0.46      0.63        37\n",
      "       B-ORG       1.00      1.00      1.00        24\n",
      "       I-ORG       0.97      0.98      0.98     10001\n",
      "       I-PER       0.99      0.99      0.99     11128\n",
      "       B-LOC       1.00      0.82      0.90        11\n",
      "       I-LOC       0.99      0.98      0.98      8286\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     34043\n",
      "   macro avg       0.99      0.88      0.92     34043\n",
      "weighted avg       0.98      0.98      0.98     34043\n",
      "\n",
      "0.9807887647396547\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf1 = CRF(algorithm='l2sgd',\n",
    "          max_iterations=50,\n",
    "          all_possible_transitions=False)\n",
    "\n",
    "#training model\n",
    "crf1.fit(X=X_train, y=y_train)\n",
    "\n",
    "#generate predictions\n",
    "pred = crf1.predict(X_train)\n",
    "#generate report on entire model\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_train,labels=sub_labels)\n",
    "print(report)\n",
    "score=flat_f1_score(y_pred=pred, y_true=y_train,average='micro',labels=sub_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2:\n",
    "- Algorithm :Stochastic Gradient descent\n",
    "- L2 regularization (c2=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      I-MISC       0.98      0.98      0.98      4556\n",
      "      B-MISC       1.00      0.70      0.83        37\n",
      "       B-ORG       1.00      1.00      1.00        24\n",
      "       I-ORG       0.99      0.97      0.98     10001\n",
      "       I-PER       0.99      0.99      0.99     11128\n",
      "       B-LOC       1.00      0.91      0.95        11\n",
      "       I-LOC       0.99      0.98      0.99      8286\n",
      "\n",
      "   micro avg       0.99      0.98      0.98     34043\n",
      "   macro avg       0.99      0.93      0.96     34043\n",
      "weighted avg       0.99      0.98      0.98     34043\n",
      "\n",
      "0.9849654012423094\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf2 = CRF(algorithm='l2sgd',\n",
    "          c2=0.1,\n",
    "          max_iterations=50,\n",
    "          all_possible_transitions=False)\n",
    "\n",
    "#training model\n",
    "crf2.fit(X=X_train, y=y_train)\n",
    "         \n",
    "#generate predictions\n",
    "pred = crf2.predict(X_train)\n",
    "\n",
    "#generate report on entire model\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_train,labels=sub_labels)\n",
    "print(report)\n",
    "\n",
    "score=flat_f1_score(y_pred=pred, y_true=y_train,average='micro',labels=sub_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "- Algorithm : Gradient descent using the L-BFGS method\n",
    "- L1 regularization (c2=0)\n",
    "- L2 regularization (c2=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhoperoberts\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      I-MISC       0.73      0.52      0.60      4556\n",
      "      B-MISC       0.00      0.00      0.00        37\n",
      "       B-ORG       0.00      0.00      0.00        24\n",
      "       I-ORG       0.75      0.69      0.72     10001\n",
      "       I-PER       0.82      0.84      0.83     11128\n",
      "       B-LOC       0.00      0.00      0.00        11\n",
      "       I-LOC       0.74      0.78      0.76      8286\n",
      "\n",
      "   micro avg       0.77      0.74      0.75     34043\n",
      "   macro avg       0.43      0.40      0.42     34043\n",
      "weighted avg       0.76      0.74      0.75     34043\n",
      "\n",
      "0.7507157310949563\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf3 = CRF(algorithm='lbfgs',\n",
    "          #c1=0.1,\n",
    "          #c2=0.1,\n",
    "          max_iterations=50,\n",
    "          all_possible_transitions=False)\n",
    "\n",
    "#training model\n",
    "crf3.fit(X=X_train, y=y_train)\n",
    "\n",
    "#generate predictions\n",
    "pred = crf3.predict(X_train)\n",
    "\n",
    "#generate report on entire model\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_train,labels=sub_labels)\n",
    "print(report)\n",
    "\n",
    "score=flat_f1_score(y_pred=pred, y_true=y_train,average='micro',labels=sub_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4\n",
    "\n",
    "- Algorithm : Gradient descent using the L-BFGS method\n",
    "- L1 regularization (c2=0.1)\n",
    "- L2 regularization (c2=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      I-MISC       1.00      1.00      1.00      4556\n",
      "      B-MISC       1.00      0.84      0.91        37\n",
      "       B-ORG       1.00      1.00      1.00        24\n",
      "       I-ORG       1.00      1.00      1.00     10001\n",
      "       I-PER       1.00      1.00      1.00     11128\n",
      "       B-LOC       1.00      0.91      0.95        11\n",
      "       I-LOC       1.00      1.00      1.00      8286\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     34043\n",
      "   macro avg       1.00      0.96      0.98     34043\n",
      "weighted avg       1.00      1.00      1.00     34043\n",
      "\n",
      "0.9981785598871883\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf4 = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=50,\n",
    "          all_possible_transitions=False)\n",
    "\n",
    "#training model\n",
    "crf4.fit(X=X_train, y=y_train)\n",
    "\n",
    "#generate predictions\n",
    "pred = crf4.predict(X_train)\n",
    "\n",
    "#generate report on entire model\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_train,labels=sub_labels)\n",
    "print(report)\n",
    "\n",
    "score=flat_f1_score(y_pred=pred, y_true=y_train,average='micro',labels=sub_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhoperoberts\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      I-MISC       0.75      0.77      0.76       909\n",
      "      B-MISC       0.00      0.00      0.00         9\n",
      "       B-ORG       0.00      0.00      0.00         5\n",
      "       I-ORG       0.81      0.78      0.80      2491\n",
      "       I-PER       0.90      0.89      0.89      2773\n",
      "       B-LOC       0.00      0.00      0.00         6\n",
      "       I-LOC       0.86      0.87      0.87      1919\n",
      "\n",
      "   micro avg       0.85      0.84      0.84      8112\n",
      "   macro avg       0.48      0.47      0.47      8112\n",
      "weighted avg       0.85      0.84      0.84      8112\n",
      "\n",
      "0.8416806305467635\n"
     ]
    }
   ],
   "source": [
    "#prediction with best performaning model\n",
    "pred = crf4.predict(X_test)\n",
    "\n",
    "#generate report on entire model\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_test,labels=sub_labels)\n",
    "print(report)\n",
    "\n",
    "score=flat_f1_score(y_pred=pred, y_true=y_test,average='micro',labels=sub_labels)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
