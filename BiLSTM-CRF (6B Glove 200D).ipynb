{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bi-LSTM-CRF (6B Glove 200D)",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYs0s57M3jAf",
        "colab_type": "code",
        "outputId": "4fe269ac-6de8-4d29-bb43-74976e4867a4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e7291f80-8c2c-4076-823c-5bb91d3d2b22\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e7291f80-8c2c-4076-823c-5bb91d3d2b22\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving prepro.py to prepro (3).py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEI15-hK3sQ2",
        "colab_type": "code",
        "outputId": "663542d3-2403-416c-a832-88018cd197db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "!sudo pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install sklearn_crfsuite\n",
        "!pip install keras==2.2.4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-jff5o9ef\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-jff5o9ef\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.3.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.17.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101065 sha256=3af1ea5072d3d347cbe4b5051798a148d9d63dc83ee354b86b28d30a2ff03cf5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z_3urag8/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.5)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.9.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvLtrysY3xZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#cusotm packages\n",
        "from prepro import readstring\n",
        "\n",
        "#keras and tensorflow packages\n",
        "from keras.layers.merge import add\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy\n",
        "from keras_contrib.metrics import crf_accuracy\n",
        "\n",
        "\n",
        "#evaluation\n",
        "from sklearn_crfsuite.metrics import flat_classification_report,flat_f1_score,flat_precision_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ5UL1PL39-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import data from my github repo\n",
        "train_url = \"https://raw.githubusercontent.com/deanhoperobertson/Named-Enitty-Recognition/master/Data/train.txt\"\n",
        "test_url = \"https://raw.githubusercontent.com/deanhoperobertson/Named-Enitty-Recognition/master/Data/test.txt\"\n",
        "train = urllib.request.urlopen(train_url).read()\n",
        "test = urllib.request.urlopen(test_url).read()\n",
        "train = train.decode('utf-8')\n",
        "test = test.decode('utf-8')\n",
        "\n",
        "def readstring(filename, meth):\n",
        "    f = filename.split('\\n')\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for line in f:\n",
        "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
        "            if len(sentence) > 0:\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "            continue\n",
        "        splits = line.split(' ')\n",
        "        if meth.lower()==\"numbers\":\n",
        "            sentence.append([hasNumbers(splits[0]), splits[-1].strip()])\n",
        "        else:\n",
        "            sentence.append([splits[0], splits[-1].strip()])\n",
        "    if len(sentence) > 0:\n",
        "        sentences.append(sentence)\n",
        "        sentence = []\n",
        "    return sentences\n",
        "\n",
        "def hasNumbers(inputString):\n",
        "    if re.search(r'\\d', inputString):\n",
        "        return \"__\"\n",
        "    else:return(inputString)\n",
        "\n",
        "#preproces the txt file\n",
        "train_data = readstring(train,\"Numbers\")\n",
        "test_data = readstring(test,\"Numbers\")\n",
        "\n",
        "#create corpus\n",
        "corpus = train_data.copy()\n",
        "corpus.extend(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQSami9V4FbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reformat_data(data,meth):\n",
        "  if meth.lower() == \"data\":\n",
        "    i=0\n",
        "  else: i=1\n",
        "  train = []\n",
        "  output= []\n",
        "  for sentence in data:\n",
        "    words=[]\n",
        "    for x in sentence:\n",
        "      words.append(x[i])\n",
        "    train.append(words)\n",
        "\n",
        "  for i in train:\n",
        "    string = ' '.join(i)\n",
        "    output.append(string)\n",
        "  return output\n",
        "\n",
        "def get_max_length(corpus):\n",
        "  length = []\n",
        "  for sentence in corpus:\n",
        "    length.append(len(sentence))\n",
        "  return int(max(length))\n",
        "\n",
        "def number_of_tags(corpus):\n",
        "  tags=[]\n",
        "  for sentence in corpus:\n",
        "    for tag in sentence:\n",
        "      tags.append(tag[1])\n",
        "  return int(len(list(set(tags))))\n",
        "\n",
        "\n",
        "MAX_LEN = get_max_length(corpus)\n",
        "N_tags = number_of_tags(corpus)\n",
        "\n",
        "train = reformat_data(train_data,\"data\")\n",
        "test = reformat_data(test_data,\"data\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOyKFaZ64Piy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a tokenizer\n",
        "token_word = text.Tokenizer(char_level=False, lower=True, filters=\"}\", oov_token='UNK')\n",
        "token_word.fit_on_texts(train)\n",
        "\n",
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "X_train = sequence.pad_sequences(token_word.texts_to_sequences(train), maxlen=MAX_LEN,padding=\"post\")\n",
        "X_test = sequence.pad_sequences(token_word.texts_to_sequences(test), maxlen=MAX_LEN,padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "791RIPxLFdE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = reformat_data(train_data,\"tags\")\n",
        "test = reformat_data(test_data,\"tags\")\n",
        "\n",
        "# create a tokenizer\n",
        "token_tag = text.Tokenizer(char_level=False, lower=False, filters=\"}\")\n",
        "token_tag.fit_on_texts(train)\n",
        "\n",
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "Y = sequence.pad_sequences(token_tag.texts_to_sequences(train), maxlen=MAX_LEN,padding=\"post\")\n",
        "# One-Hot encode categorical labels\n",
        "Y_train = [to_categorical(i, num_classes=N_tags+1) for i in Y]\n",
        "\n",
        "Y = sequence.pad_sequences(token_tag.texts_to_sequences(test), maxlen=MAX_LEN,padding=\"post\")\n",
        "# One-Hot encode categorical labels\n",
        "Y_test = [to_categorical(i, num_classes=N_tags+1) for i in Y]\n",
        "\n",
        "#add padding \n",
        "token_tag.index_word[0]=\"PAD\"\n",
        "sub_label = list(token_tag.index_word.values())\n",
        "sub_label.remove('O')\n",
        "sub_label.remove('PAD')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADOS66iMHYkr",
        "colab_type": "code",
        "outputId": "5ed1eda5-1b40-4e14-aa2d-60cc9d0e9df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDX21YJbJy6N",
        "colab_type": "code",
        "outputId": "23a8f15d-5f02-4b0f-fc58-36db26f70454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#root_path = \"/content/drive/My Drive/glove.6B.50d.txt\"\n",
        "#root_path = \"/content/drive/My Drive/glove.6B.100d.txt\"\n",
        "root_path = \"/content/drive/My Drive/glove.6B.200d.txt\"\n",
        "#root_path = \"/content/drive/My Drive/glove.6B.300d.txt\"\n",
        "#root_path = \"/content/drive/My Drive/wiki-news-300d-1M.vec\"\n",
        "\n",
        "embeddings_index={}\n",
        "f = open(root_path, encoding = \"utf-8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QCSd3QKJ-Cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create emedding matrix\n",
        "EMBEDDING=int(root_path.split(\".\")[-2][:-1])\n",
        "word_index = token_word.word_index\n",
        "embedding_matrix = np.zeros((len(token_word.word_index) + 1, EMBEDDING))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all-zeros.\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHwzSe4s8cj",
        "colab_type": "code",
        "outputId": "24369778-6afc-4d78-a7e6-a0ec1e36a756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "checks=[]\n",
        "words=[]\n",
        "for i in range(0,len(token_word.word_index)+1):\n",
        "  if embedding_matrix[i][0] == 0.0:\n",
        "    checks.append(1)\n",
        "    words.append(list(token_word.word_index.items())[i-1][0])\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "print(\"Missing words from Embeddings: %d (%.2f%%)\" %(len(checks),(len(checks)/len(token_word.word_index)*100)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Missing words from Embeddings: 1218 (7.10%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLUxQqI8Md4N",
        "colab_type": "text"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJXcEXJYMg4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model definition\n",
        "\n",
        "input = Input(shape=(MAX_LEN,))\n",
        "\n",
        "model_2 = Embedding(len(token_word.word_index) + 1,output_dim=EMBEDDING,\n",
        "                  weights=[embedding_matrix],input_length=MAX_LEN,\n",
        "                  trainable=False,mask_zero=True)(input)\n",
        "\n",
        "model_2 = Bidirectional(LSTM(units=300, return_sequences=True,\n",
        "                           recurrent_dropout=0.2))(model_2)\n",
        "\n",
        "model_2 = Bidirectional(LSTM(units=300, return_sequences=True,\n",
        "                           recurrent_dropout=0.2))(model_2)\n",
        "\n",
        "model_2 = TimeDistributed(Dense(50, activation=\"relu\"))(model_2)\n",
        "crf = CRF(N_tags+1)  # CRF layer\n",
        "out = crf(model_2)  # output\n",
        "model_2 = Model(input, out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA9_8iSPMiyn",
        "colab_type": "code",
        "outputId": "5e21f202-3ccd-47ce-ac34-a4c2403d5ffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "model_2.compile(optimizer='adam', loss=crf_loss,metrics=[crf_viterbi_accuracy])\n",
        "model_2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 124)               0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 124, 200)          3433000   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 124, 600)          1202400   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 124, 600)          2162400   \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 124, 50)           30050     \n",
            "_________________________________________________________________\n",
            "crf_2 (CRF)                  (None, 124, 9)            558       \n",
            "=================================================================\n",
            "Total params: 6,828,408\n",
            "Trainable params: 3,395,408\n",
            "Non-trainable params: 3,433,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjSNmgV3OyH6",
        "colab_type": "code",
        "outputId": "978ea221-a5ee-4a01-9466-57079f1a99d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "BATCH_SIZE = 200\n",
        "EPOCHS=10\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
        "history = model_2.fit(X_train, np.array(Y_train), batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.2, verbose=1,callbacks=[early_stopping])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11232 samples, validate on 2809 samples\n",
            "Epoch 1/10\n",
            "11232/11232 [==============================] - 118s 10ms/step - loss: 40.5193 - crf_viterbi_accuracy: 0.8578 - val_loss: 35.3189 - val_crf_viterbi_accuracy: 0.9169\n",
            "Epoch 2/10\n",
            "11232/11232 [==============================] - 113s 10ms/step - loss: 40.1360 - crf_viterbi_accuracy: 0.9377 - val_loss: 35.2410 - val_crf_viterbi_accuracy: 0.9419\n",
            "Epoch 3/10\n",
            "11232/11232 [==============================] - 113s 10ms/step - loss: 40.0806 - crf_viterbi_accuracy: 0.9552 - val_loss: 35.2045 - val_crf_viterbi_accuracy: 0.9525\n",
            "Epoch 4/10\n",
            "11232/11232 [==============================] - 113s 10ms/step - loss: 40.0501 - crf_viterbi_accuracy: 0.9637 - val_loss: 35.1859 - val_crf_viterbi_accuracy: 0.9585\n",
            "Epoch 5/10\n",
            "11232/11232 [==============================] - 110s 10ms/step - loss: 40.0289 - crf_viterbi_accuracy: 0.9703 - val_loss: 35.1730 - val_crf_viterbi_accuracy: 0.9614\n",
            "Epoch 6/10\n",
            "11232/11232 [==============================] - 112s 10ms/step - loss: 40.0139 - crf_viterbi_accuracy: 0.9747 - val_loss: 35.1642 - val_crf_viterbi_accuracy: 0.9650\n",
            "Epoch 7/10\n",
            "11232/11232 [==============================] - 111s 10ms/step - loss: 40.0046 - crf_viterbi_accuracy: 0.9773 - val_loss: 35.1642 - val_crf_viterbi_accuracy: 0.9657\n",
            "Epoch 8/10\n",
            "11232/11232 [==============================] - 109s 10ms/step - loss: 39.9941 - crf_viterbi_accuracy: 0.9814 - val_loss: 35.1709 - val_crf_viterbi_accuracy: 0.9671\n",
            "Epoch 9/10\n",
            "11232/11232 [==============================] - 110s 10ms/step - loss: 39.9883 - crf_viterbi_accuracy: 0.9834 - val_loss: 35.1644 - val_crf_viterbi_accuracy: 0.9656\n",
            "Epoch 10/10\n",
            "11232/11232 [==============================] - 111s 10ms/step - loss: 39.9824 - crf_viterbi_accuracy: 0.9856 - val_loss: 35.1654 - val_crf_viterbi_accuracy: 0.9684\n",
            "CPU times: user 28min 35s, sys: 2min 55s, total: 31min 30s\n",
            "Wall time: 18min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOZlNNM-YcZv",
        "colab_type": "text"
      },
      "source": [
        "## Predict On Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEw08HSrSHG2",
        "colab_type": "code",
        "outputId": "4c9c1653-cc7e-4979-9f74-0708ceb1433b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "pred = model_2.predict(X_train, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14041/14041 [==============================] - 287s 20ms/step\n",
            "CPU times: user 7min 19s, sys: 1min 7s, total: 8min 26s\n",
            "Wall time: 4min 47s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOlSUB8BShcQ",
        "colab_type": "code",
        "outputId": "fc010c33-b315-4b53-bef1-669ab0bd5c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# TRain Eval\n",
        "preds = np.argmax(pred, axis=-1)\n",
        "y_tr_true = np.argmax(Y_train, -1)\n",
        "\n",
        "# Convert the index to tag\n",
        "pred_tag = [[token_tag.index_word[i] for i in row] for row in preds]\n",
        "y_tr_true_tag = [[token_tag.index_word[i] for i in row] for row in y_tr_true]\n",
        "                 \n",
        "                 \n",
        "report = flat_classification_report(y_pred=pred_tag, y_true=y_tr_true_tag,labels=sub_label)\n",
        "print(report)\n",
        "#F1 Score\n",
        "score=flat_f1_score(y_pred=pred_tag, y_true=y_tr_true_tag,average='micro',labels=sub_label)\n",
        "print(score)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-PER       0.98      0.98      0.98     11128\n",
            "       I-ORG       0.93      0.89      0.91     10001\n",
            "       I-LOC       0.97      0.93      0.95      8286\n",
            "      I-MISC       0.93      0.85      0.89      4556\n",
            "      B-MISC       0.50      0.22      0.30        37\n",
            "       B-ORG       1.00      1.00      1.00        24\n",
            "       B-LOC       1.00      0.27      0.43        11\n",
            "\n",
            "   micro avg       0.96      0.92      0.94     34043\n",
            "   macro avg       0.90      0.73      0.78     34043\n",
            "weighted avg       0.96      0.92      0.94     34043\n",
            "\n",
            "0.9387901633458985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-xpkf6Dg7Zg",
        "colab_type": "text"
      },
      "source": [
        "## Predict On Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJsXpwO2flwh",
        "colab_type": "code",
        "outputId": "c3c848b2-bf93-45dc-fa24-0f61b2fb97d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "pred = model_2.predict(X_test, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3453/3453 [==============================] - 72s 21ms/step\n",
            "CPU times: user 1min 49s, sys: 16.8 s, total: 2min 6s\n",
            "Wall time: 1min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ8TiP-dhc35",
        "colab_type": "code",
        "outputId": "4c70cbbd-2bc0-400a-e5d7-6befaaa4711b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# TRain Eval\n",
        "#pred_cat = model.predict(X_tr)\n",
        "preds = np.argmax(pred, axis=-1)\n",
        "y_tr_true = np.argmax(Y_test, -1)\n",
        "\n",
        "# Convert the index to tag\n",
        "pred_tag = [[token_tag.index_word[i] for i in row] for row in preds]\n",
        "y_tr_true_tag = [[token_tag.index_word[i] for i in row] for row in y_tr_true]\n",
        "                 \n",
        "                 \n",
        "report = flat_classification_report(y_pred=pred_tag, y_true=y_tr_true_tag, labels=sub_label)\n",
        "print(report)\n",
        "\n",
        "score=flat_f1_score(y_pred=pred_tag, y_true=y_tr_true_tag,average='micro', labels=sub_label)\n",
        "print(score)     "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-PER       0.94      0.89      0.91      2773\n",
            "       I-ORG       0.82      0.73      0.77      2491\n",
            "       I-LOC       0.90      0.84      0.87      1919\n",
            "      I-MISC       0.74      0.66      0.70       909\n",
            "      B-MISC       0.00      0.00      0.00         9\n",
            "       B-ORG       0.00      0.00      0.00         5\n",
            "       B-LOC       0.00      0.00      0.00         6\n",
            "\n",
            "   micro avg       0.87      0.80      0.84      8112\n",
            "   macro avg       0.49      0.44      0.46      8112\n",
            "weighted avg       0.87      0.80      0.83      8112\n",
            "\n",
            "0.8350389393061725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR4-YXy6O7C7",
        "colab_type": "code",
        "outputId": "6b51c232-36f9-41fe-971e-937b5e89978c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()                       \n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "model_2.save('model_200D.h5')\n",
        "model_file = drive.CreateFile({'title' : 'model_200D.h5'})                       \n",
        "model_file.SetContentFile('model_200D.h5')                       \n",
        "model_file.Upload()\n",
        "print(\"Saved Model to Google Drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved Model to Google Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX1n1YxIEHWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
