{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Random Field Model (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Custom models\n",
    "from prepro import readfile, get_sentence, is_number, extract_words,get_label,partial_tags\n",
    "\n",
    "#Model\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "#Evalulation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn_crfsuite.metrics import flat_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from my github repo\n",
    "test = readfile(\"test.txt\")\n",
    "train =readfile(\"train.txt\")\n",
    "\n",
    "# filenames = ['train.txt', 'valid.txt']\n",
    "# with open('Combined.txt', 'w') as outfile:\n",
    "#     for fname in filenames:\n",
    "#         with open(fname) as infile:\n",
    "#             for line in infile:\n",
    "#                 outfile.write(line)\n",
    "                \n",
    "# train =readfile(\"Combined.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthographic Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special Features:\n",
    "def count_vowel(word):\n",
    "    '''\n",
    "    Function returns the number of vowels in token\n",
    "    '''\n",
    "    return sum(list(map(word.lower().count, \"aeiou\")))\n",
    "\n",
    "def dash(word):\n",
    "    '''\n",
    "    The Function returns whether or not the token contains a dash\n",
    "    '''\n",
    "    return 1 if \"-\" in word else 0\n",
    "\n",
    "def count_consonants(word):\n",
    "    '''\n",
    "    The Function returns the number of consonants in a token\n",
    "    '''\n",
    "    vowels=\"aeiou\"\n",
    "    return sum(i not in vowels for i in word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sentence,i):\n",
    "    word = sentence[i]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'Prefix_2': word[:2],\n",
    "        'Prefix_3': word[:3], \n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.islower()': word.islower(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.isalpha()': word.isalpha(),\n",
    "        'word.isalnum()': word.isalnum(), \n",
    "        \"vowels\": count_vowel(word),\n",
    "        \"dash\": dash(word),\n",
    "        \"consonants\": count_consonants(word),\n",
    "        'Suffix_2': word[-2:],\n",
    "        'Suffix_3': word[-3:],\n",
    "        \n",
    "    }\n",
    "    if i > 0:\n",
    "        '''\n",
    "        Get the token before in the sentence\n",
    "        '''\n",
    "        word1 = sentence[i-1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word Prefix_2': word1[:2],\n",
    "            '-1:word Prefix_3': word1[:3], \n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.islower()': word1.lower(),\n",
    "            '-1:word.isdigit()': word1.isdigit(),\n",
    "            '-1:word.isalpha()': word1.isalpha(),\n",
    "            '-1:word.isalnum()': word1.isalnum(), \n",
    "            \"-1:word.vowels\": count_vowel(word1),\n",
    "            \"-1:word.dash\": dash(word1),\n",
    "            \"-1:word.consonants\": count_consonants(word1),\n",
    "            '-1:word.Suffix_2': word1[-2:],\n",
    "            '-1:word.Suffix_3': word1[-3:],\n",
    "        })\n",
    "    else:\n",
    "        features['START'] = True\n",
    "        \n",
    "    if i < len(sentence)-1:\n",
    "        '''\n",
    "        Get the token after in the sentence\n",
    "        '''\n",
    "        word1 = sentence[i+1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.Prefix_2': word1[:2],\n",
    "            '+1:word.Prefix_3': word1[:3], \n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.islower()': word1.lower(),\n",
    "            '+1:word.isdigit()': word1.isdigit(),\n",
    "            '+1:word.isalpha()': word1.isalpha(),\n",
    "            '+1:word.isalnum()': word1.isalnum(), \n",
    "            \"+1:word.vowels\": count_vowel(word1),\n",
    "            \"+1:word.dash\": dash(word1),\n",
    "            \"+1:word.consonants\": count_consonants(word1),\n",
    "            '+1:word.Suffix_2': word1[-2:],\n",
    "            '+1:word.Suffix_3': word1[-3:],\n",
    "        })\n",
    "    else:\n",
    "        features['END'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def get_all_sentences(dataset):\n",
    "    sentences=[]\n",
    "    for i in range(len(dataset)):\n",
    "        sentences.append(get_sentence(dataset,i+1))\n",
    "    return sentences\n",
    "\n",
    "def get_all_labels(dataset):\n",
    "    labels=[]\n",
    "    for i in range(len(dataset)):\n",
    "        #labels.append(partial_tags(get_label(dataset,i+1)))\n",
    "        labels.append(get_label(dataset,i+1))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "#get the first sentence\n",
    "sent = get_sentence(train,1)\n",
    "#label = partial_tags(get_label(train,1))\n",
    "label = get_label(train,1)\n",
    "\n",
    "#print out first sentence\n",
    "print(sent)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applt feature engineering\n",
    "train_sents = get_all_sentences(train)\n",
    "train_labels = get_all_labels(train)\n",
    "test_sents = get_all_sentences(test)\n",
    "test_labels = get_all_labels(test)\n",
    "\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = train_labels\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = test_labels\n",
    "\n",
    "\n",
    "sub_labels=list(set([item for sublist in train_labels for item in sublist]))\n",
    "sub_labels.remove(\"O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Grid Search of Full Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "crf_grid = CRF(algorithm='lbfgs',\n",
    "          max_iterations=50,\n",
    "          all_possible_transitions=False)\n",
    "\n",
    "parameters = {'c1':[0.1,0.3],\n",
    "             'c2':[0.2,0.0]}\n",
    "\n",
    "f1_scorer = make_scorer(flat_f1_score,\n",
    "                        average='micro',\n",
    "                        labels=sub_labels)\n",
    "\n",
    "grid = GridSearchCV(crf_grid, \n",
    "                    parameters,\n",
    "                    #n_jobs=-1,\n",
    "                    scoring =f1_scorer,\n",
    "                    verbose=2,\n",
    "                    return_train_score=True,\n",
    "                    cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] c1=0.1, c2=0.2 ..................................................\n",
      "[CV] ................................... c1=0.1, c2=0.2, total=  16.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] c1=0.1, c2=0.2 ..................................................\n",
      "[CV] ................................... c1=0.1, c2=0.2, total=  16.3s\n",
      "[CV] c1=0.1, c2=0.2 ..................................................\n",
      "[CV] ................................... c1=0.1, c2=0.2, total=  14.6s\n",
      "[CV] c1=0.1, c2=0.0 ..................................................\n",
      "[CV] ................................... c1=0.1, c2=0.0, total=  16.4s\n",
      "[CV] c1=0.1, c2=0.0 ..................................................\n",
      "[CV] ................................... c1=0.1, c2=0.0, total=  16.1s\n",
      "[CV] c1=0.1, c2=0.0 ..................................................\n",
      "[CV] ................................... c1=0.1, c2=0.0, total=  14.1s\n",
      "[CV] c1=0.3, c2=0.2 ..................................................\n",
      "[CV] ................................... c1=0.3, c2=0.2, total=  15.6s\n",
      "[CV] c1=0.3, c2=0.2 ..................................................\n",
      "[CV] ................................... c1=0.3, c2=0.2, total=  15.8s\n",
      "[CV] c1=0.3, c2=0.2 ..................................................\n",
      "[CV] ................................... c1=0.3, c2=0.2, total=  14.0s\n",
      "[CV] c1=0.3, c2=0.0 ..................................................\n",
      "[CV] ................................... c1=0.3, c2=0.0, total=  15.9s\n",
      "[CV] c1=0.3, c2=0.0 ..................................................\n",
      "[CV] ................................... c1=0.3, c2=0.0, total=  15.6s\n",
      "[CV] c1=0.3, c2=0.0 ..................................................\n",
      "[CV] ................................... c1=0.3, c2=0.0, total=  14.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_results=grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 0.1, 'c2': 0.0}\n",
      "best CV score: 0.8642938170486253\n",
      "0.863527 (0.015570) with: {'c1': 0.1, 'c2': 0.2}\n",
      "0.864294 (0.012664) with: {'c1': 0.1, 'c2': 0.0}\n",
      "0.859081 (0.014579) with: {'c1': 0.3, 'c2': 0.2}\n",
      "0.860446 (0.013810) with: {'c1': 0.3, 'c2': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print('best params:', grid_results.best_params_)\n",
    "print('best CV score:',grid_results.best_score_)\n",
    "\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Predict on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-LOC       0.99      1.00      1.00      8286\n",
      "       B-LOC       1.00      1.00      1.00        11\n",
      "      I-MISC       0.99      1.00      0.99      4556\n",
      "       I-PER       1.00      1.00      1.00     11128\n",
      "       B-ORG       1.00      1.00      1.00        24\n",
      "      B-MISC       0.96      0.73      0.83        37\n",
      "       I-ORG       1.00      0.99      0.99     10001\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     34043\n",
      "   macro avg       0.99      0.96      0.97     34043\n",
      "weighted avg       1.00      1.00      1.00     34043\n",
      "\n",
      "Traning f1 Score = 0.9961362734871969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhoperoberts\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-LOC       0.83      0.87      0.85      1919\n",
      "       B-LOC       0.00      0.00      0.00         6\n",
      "      I-MISC       0.78      0.77      0.78       909\n",
      "       I-PER       0.88      0.87      0.88      2773\n",
      "       B-ORG       0.00      0.00      0.00         5\n",
      "      B-MISC       0.00      0.00      0.00         9\n",
      "       I-ORG       0.81      0.77      0.79      2491\n",
      "\n",
      "   micro avg       0.84      0.83      0.83      8112\n",
      "   macro avg       0.47      0.47      0.47      8112\n",
      "weighted avg       0.83      0.83      0.83      8112\n",
      "\n",
      "Test f1 Score = 0.8323112184847922\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf4 = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.0,\n",
    "          max_iterations=50,\n",
    "          all_possible_transitions=False)\n",
    "\n",
    "#training model\n",
    "crf4.fit(X=X_train, y=y_train)\n",
    "\n",
    "#TRAIN SET\n",
    "pred = crf4.predict(X_train)\n",
    "#generate report on entire model\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_train,labels=sub_labels)\n",
    "print(report)\n",
    "score=flat_f1_score(y_pred=pred, y_true=y_train,average='micro',labels=sub_labels)\n",
    "print(\"Traning f1 Score =\",score)\n",
    "\n",
    "\n",
    "#TEST SET\n",
    "pred = crf4.predict(X_test)\n",
    "#generate report on entire model\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_test,labels=sub_labels)\n",
    "print(report)\n",
    "score=flat_f1_score(y_pred=pred, y_true=y_test,average='micro',labels=sub_labels)\n",
    "print(\"Test f1 Score =\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
