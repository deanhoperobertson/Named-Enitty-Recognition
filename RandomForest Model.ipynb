{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (with Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Custom models\n",
    "from prepro import readfile, get_sentence, is_number, extract_words,partial_tags\n",
    "\n",
    "\n",
    "#Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Evalulation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from my github repo\n",
    "train = readfile(\"train.txt\")\n",
    "corpus = train.copy()\n",
    "test = readfile(\"test.txt\")\n",
    "\n",
    "#create corpus\n",
    "corpus.extend(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "tags = []\n",
    "for sentence in corpus:\n",
    "    for word in sentence:\n",
    "        words.append(word[0])\n",
    "        tags.append(word[1])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the dataset:  27316\n",
      "Number of tags in the dataset:  5\n"
     ]
    }
   ],
   "source": [
    "tags = partial_tags(tags)\n",
    "words=list(words)\n",
    "n_words = len(set(words))\n",
    "n_tags = len(set(tags))\n",
    "\n",
    "labels=list(set(tags))\n",
    "labels.remove('O')\n",
    "\n",
    "print(\"Number of words in the dataset: \", n_words)\n",
    "print(\"Number of tags in the dataset: \", n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set\n",
    "train_words, train_tags = extract_words(train)\n",
    "train_tags=partial_tags(train_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthographic  Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vowel(word):\n",
    "    return sum(list(map(word.lower().count, \"aeiou\")))\n",
    "\n",
    "def dash(word):\n",
    "    return 1 if \"-\" in word else 0\n",
    "\n",
    "def count_consonants(word):\n",
    "    vowels=\"aeiou\"\n",
    "    return sum(i not in vowels for i in word)\n",
    "    \n",
    "def feature_map(word):\n",
    "    '''Simple feature map with 10 features'''\n",
    "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
    "                     word.isdigit(),  word.isalpha(),word.isalnum(),count_vowel(word),\n",
    "                    dash(word), count_consonants(word)]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_words = [feature_map(word) for word in train_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 2, 0, 1, 1, 2, 0, 2]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier (with Features)\n",
    "\n",
    "We use feature engineering here as Random Forest classifiers are not typical used for sequencs classification and thus need an input dataframe with a least two columns. Therefore we need train the classifier using feature engineered data with 10 features results in a dataframe of 10 columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train \n",
    "pred = cross_val_predict(RandomForestClassifier(n_estimators=20), X=train_feature_words, y=train_tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         PER       0.36      0.76      0.49     11128\n",
      "         LOC       0.48      0.20      0.29      8297\n",
      "         ORG       0.42      0.28      0.34     10025\n",
      "        MISC       0.44      0.12      0.19      4593\n",
      "\n",
      "   micro avg       0.39      0.40      0.39     34043\n",
      "   macro avg       0.42      0.34      0.32     34043\n",
      "weighted avg       0.42      0.40      0.35     34043\n",
      "\n",
      "F1 Score: 0.3538755235011891\n"
     ]
    }
   ],
   "source": [
    "#generate report on entire model\n",
    "report = classification_report(y_pred=pred, y_true=train_tags,labels=labels)\n",
    "f1= f1_score(y_pred=pred, y_true=train_tags,average='weighted',labels=labels)\n",
    "print(report)\n",
    "print(\"F1 Score:\",f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test set\n",
    "test_words, test_tags = extract_words(test)\n",
    "test_tags=partial_tags(test_tags)\n",
    "\n",
    "#apply feature engineering\n",
    "test_feature_words = [feature_map(word) for word in test_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and fit\n",
    "clf = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "clf.fit(train_feature_words,train_tags)\n",
    "\n",
    "pred = clf.predict(test_feature_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         PER       0.37      0.78      0.50      2773\n",
      "         LOC       0.48      0.20      0.28      1925\n",
      "         ORG       0.43      0.26      0.32      2496\n",
      "        MISC       0.37      0.14      0.20       918\n",
      "\n",
      "   micro avg       0.39      0.41      0.40      8112\n",
      "   macro avg       0.41      0.34      0.33      8112\n",
      "weighted avg       0.41      0.41      0.36      8112\n",
      "\n",
      "F1 Score: 0.3601999395995972\n"
     ]
    }
   ],
   "source": [
    "#generate report on entire model\n",
    "report = classification_report(y_pred=pred, y_true=test_tags,labels=labels)\n",
    "f1= f1_score(y_pred=pred, y_true=test_tags,average='weighted',labels=labels)\n",
    "print(report)\n",
    "print(\"F1 Score:\",f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Context to Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the sentences in the form of a list\n",
    "def get_all_sentences(dataset):\n",
    "    sentences=[]\n",
    "    for i in range(len(dataset)):\n",
    "        sentences.append(get_sentence(dataset,i+1))\n",
    "    return sentences\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [feature_map2(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def feature_map2(sentence,i):\n",
    "    word = sentence[i]\n",
    "    \n",
    "    '''Simple feature map with 10 features'''\n",
    "    primary_word = np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
    "                     word.isdigit(),  word.isalpha(),word.isalnum(),count_vowel(word),\n",
    "                    dash(word), count_consonants(word)]).tolist()\n",
    "    if i > 0:\n",
    "        word1 = sentence[i-1]\n",
    "        primary_word.extend(np.array([word1.istitle(), word1.islower(), word1.isupper(), len(word1),\n",
    "                     word1.isdigit(),  word1.isalpha(),word1.isalnum(),count_vowel(word1),\n",
    "                    dash(word1), count_consonants(word1)]).tolist())\n",
    "    else: \n",
    "        word1 = sentence[-i]\n",
    "        primary_word.extend(np.array([word1.istitle(), word1.islower(), word1.isupper(), len(word1),\n",
    "                     word1.isdigit(),  word1.isalpha(),word1.isalnum(),count_vowel(word1),\n",
    "                    dash(word1), count_consonants(word1)]).tolist())\n",
    "    \n",
    "    if i < len(sentence)-1:\n",
    "        word1 = sentence[i+1]\n",
    "        primary_word.extend(np.array([word1.istitle(), word1.islower(), word1.isupper(), len(word1),\n",
    "                     word1.isdigit(),  word1.isalpha(),word1.isalnum(),count_vowel(word1),\n",
    "                    dash(word1), count_consonants(word1)]).tolist())\n",
    "    else:\n",
    "        word1 = sentence[0]\n",
    "        primary_word.extend(np.array([word1.istitle(), word1.islower(), word1.isupper(), len(word1),\n",
    "                     word1.isdigit(),  word1.isalpha(),word1.isalnum(),count_vowel(word1),\n",
    "                    dash(word1), count_consonants(word1)]).tolist())\n",
    "        \n",
    "    return(primary_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = get_all_sentences(train)\n",
    "\n",
    "#Applt feature engineering\n",
    "X = [sent2features(s) for s in sentences]\n",
    "\n",
    "train_feature_words = []\n",
    "for sublist in X:\n",
    "    for item in sublist:\n",
    "        train_feature_words.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train \n",
    "pred = cross_val_predict(RandomForestClassifier(n_estimators=20), X=train_feature_words, y=train_tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         PER       0.69      0.72      0.71     11128\n",
      "         LOC       0.68      0.66      0.67      8297\n",
      "         ORG       0.67      0.62      0.64     10025\n",
      "        MISC       0.57      0.52      0.54      4593\n",
      "\n",
      "   micro avg       0.67      0.65      0.66     34043\n",
      "   macro avg       0.65      0.63      0.64     34043\n",
      "weighted avg       0.67      0.65      0.66     34043\n",
      "\n",
      "F1 Score: 0.656093027063109\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_pred=pred, y_true=train_tags,labels=labels)\n",
    "f1= f1_score(y_pred=pred, y_true=train_tags,average='weighted',labels=labels)\n",
    "print(report)\n",
    "print(\"F1 Score:\",f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = get_all_sentences(test)\n",
    "\n",
    "#Applt feature engineering\n",
    "X = [sent2features(s) for s in sentences]\n",
    "\n",
    "test_feature_words = []\n",
    "for sublist in X:\n",
    "    for item in sublist:\n",
    "        test_feature_words.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and fit\n",
    "clf = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "clf.fit(train_feature_words,train_tags)\n",
    "\n",
    "pred = clf.predict(test_feature_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         PER       0.65      0.67      0.66      2773\n",
      "         LOC       0.63      0.60      0.61      1925\n",
      "         ORG       0.63      0.61      0.62      2496\n",
      "        MISC       0.46      0.46      0.46       918\n",
      "\n",
      "   micro avg       0.62      0.61      0.61      8112\n",
      "   macro avg       0.59      0.59      0.59      8112\n",
      "weighted avg       0.62      0.61      0.61      8112\n",
      "\n",
      "F1 Score: 0.6140340754306168\n"
     ]
    }
   ],
   "source": [
    "#generate report on entire model\n",
    "report = classification_report(y_pred=pred, y_true=test_tags,labels=labels)\n",
    "f1= f1_score(y_pred=pred, y_true=test_tags,average='weighted',labels=labels)\n",
    "print(report)\n",
    "print(\"F1 Score:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
