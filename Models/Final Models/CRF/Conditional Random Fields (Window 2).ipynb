{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conditional Random Fields (Window 2)",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deanhoperobertson/Named-Enitty-Recognition/blob/master/Models/Final%20Models/CRF/Conditional%20Random%20Fields%20(Window%202).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaLZPShU4C5X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "55735c8c-a2f5-4db1-86f0-6519c71bd8fc"
      },
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDtief2UV8sX"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "\n",
        "#grid search\n",
        "import scipy.stats\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "#Model\n",
        "from sklearn_crfsuite import CRF\n",
        "\n",
        "#Evalulation\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn_crfsuite.metrics import flat_classification_report, flat_f1_score, flat_recall_score, flat_precision_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICYOd0WbVYBV"
      },
      "source": [
        "def readstring(filename, meth):\n",
        "    f = filename.split('\\n')\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for line in f:\n",
        "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
        "            if len(sentence) > 0:\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "            continue\n",
        "        splits = line.split(' ')\n",
        "        if meth.lower()==\"numbers\":\n",
        "            sentence.append([hasNumbers(splits[0]), splits[-1].strip()])\n",
        "        else:\n",
        "            sentence.append([splits[0], splits[-1].strip()])\n",
        "    if len(sentence) > 0:\n",
        "        sentences.append(sentence)\n",
        "        sentence = []\n",
        "    return sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxKta7pHV-Xz"
      },
      "source": [
        "#import data from my github repo\n",
        "train_url = \"https://raw.githubusercontent.com/deanhoperobertson/Named-Enitty-Recognition/master/Data/train.txt\"\n",
        "test_url = \"https://raw.githubusercontent.com/deanhoperobertson/Named-Enitty-Recognition/master/Data/test.txt\"\n",
        "train = urllib.request.urlopen(train_url).read()\n",
        "test = urllib.request.urlopen(test_url).read()\n",
        "train = train.decode('utf-8')\n",
        "test = test.decode('utf-8')\n",
        "\n",
        "#preproces the txt file\n",
        "train = readstring(train,\"NONE\")\n",
        "test = readstring(test, \"NONE\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1xaQzBBWRp3"
      },
      "source": [
        "## Orthographic Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47lFFjoVWEtb"
      },
      "source": [
        "#Engineered Features:\n",
        "def mix(word):\n",
        "    if word.isalnum():\n",
        "        if re.search(\"^(?=.*[a-zA-Z])(?=.*[0-9])\",word): return True\n",
        "        else: return False\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def non_intial(word):\n",
        "    '''\n",
        "    The Function the boolean if a non-initial captital letter is present\n",
        "    '''\n",
        "    return not word[1:].islower()\n",
        "\n",
        "def contain_punct(word):\n",
        "    '''\n",
        "    The Function returns the boolean if punctuations is present in token\n",
        "    '''\n",
        "    if re.match(r'^\\w+$',word):return False\n",
        "    else: return True\n",
        "    \n",
        "def apostrophe(word):\n",
        "    '''\n",
        "    The Function returns boolean if \"'s\" is present in token \n",
        "    '''\n",
        "    if word ==\"'s\":return True\n",
        "    else:return False\n",
        "    \n",
        "def word_pattern(word):\n",
        "    '''\n",
        "    The Function returns word patter feature\n",
        "    Upper Case = \"A\"\n",
        "    Lower Case = \"a\"\n",
        "    Digit = \"0\"\n",
        "    '''\n",
        "    token=\"\"\n",
        "    for i in word:\n",
        "        if i.isupper():\n",
        "            token +=\"A\"\n",
        "        elif i.islower():\n",
        "            token +=\"a\"\n",
        "        elif i.isdigit():\n",
        "            token +=\"0\"\n",
        "        else:\n",
        "            token +=str(i)\n",
        "    return token\n",
        "\n",
        "def pattern_sum(word):\n",
        "    '''\n",
        "    The Function returns the word patern without consectutive duplicates\n",
        "    '''\n",
        "    return ''.join(OrderedDict.fromkeys(word))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF_ZZSmnWvR4"
      },
      "source": [
        "def word2features(sentence,i):\n",
        "    word = sentence[i]\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()': word.lower(),\n",
        "        \n",
        "        'Prefix_2': word[:2], # prefix\n",
        "        'Prefix_3': word[:3], # prefix\n",
        "        \n",
        "        'word.istitle()': word.istitle(), #starts with caps\n",
        "        'word.isupper()': word.isupper(), #all caps\n",
        "        'word.islower()': word.islower(), #all lower case\n",
        "        'word.isdigit()': word.isdigit(), #all digits\n",
        "        'word.isalpha()': word.isalpha(), #all letters\n",
        "        \n",
        "        'word.punct()': contain_punct(word),#contains punctuation\n",
        "        'word.apost()': apostrophe(word), #is an apostrophe\n",
        "        'word.non_intial': non_intial(word), #non-initial capitals\n",
        "        'word.mix': mix(word), #mixture of letters and digits\n",
        "        'word.pattern()': word_pattern(word), #word pattern\n",
        "        'word.pattern_sum()': pattern_sum(word_pattern(word)), #word pattern summary\n",
        "        \n",
        "        'Suffix_2': word[-2:], # suffix\n",
        "        'Suffix_3': word[-3:], # suffix\n",
        "    }\n",
        "    if  i == 1 :\n",
        "        '''\n",
        "        Get the token before in the sentence\n",
        "        '''\n",
        "        word = sentence[i-1]\n",
        "        features.update({\n",
        "            \n",
        "          '-1word.lower()': word.lower(),\n",
        "          '-1Prefix_2': word[:2],\n",
        "          '-1Prefix_3': word[:3], \n",
        "          '-1word.istitle()': word.istitle(), \n",
        "          '-1word.isupper()': word.isupper(), \n",
        "          '-1word.islower()': word.islower(),\n",
        "          '-1word.isdigit()': word.isdigit(), \n",
        "          '-1word.isalpha()': word.isalpha(), \n",
        "          '-1word.punct()': contain_punct(word),\n",
        "          '-1word.apost()': apostrophe(word),\n",
        "          '-1word.non_intial': non_intial(word),\n",
        "          '-1word.mix': mix(word),\n",
        "          '-1word.pattern()': word_pattern(word),\n",
        "          '-1word.pattern_sum()': pattern_sum(word_pattern(word)), \n",
        "          '-1Suffix_2': word[-2:], \n",
        "          '-1Suffix_3': word[-3:], \n",
        "        })\n",
        "        \n",
        "    elif i>1 :\n",
        "        word1 = sentence[i-1]\n",
        "        word2 = sentence[i-2]\n",
        "        \n",
        "        features.update({\n",
        "          '-1word.lower()': word1.lower(),\n",
        "          '-1Prefix_2':word1[:2],\n",
        "          '-1Prefix_3':word1[:3], \n",
        "          '-1word.istitle()': word1.istitle(), \n",
        "          '-1word.isupper()': word1.isupper(), \n",
        "          '-1word.islower()': word1.islower(),\n",
        "          '-1word.isdigit()': word1.isdigit(), \n",
        "          '-1word.isalpha()': word1.isalpha(), \n",
        "          '-1word.punct()': contain_punct(word1),\n",
        "          '-1word.apost()': apostrophe(word1),\n",
        "          '-1word.non_intial': non_intial(word1),\n",
        "          '-1word.mix': mix(word1),\n",
        "          '-1word.pattern()': word_pattern(word1),\n",
        "          '-1word.pattern_sum()': pattern_sum(word_pattern(word1)), \n",
        "          '-1Suffix_2':word1[-2:], \n",
        "          '-1Suffix_3':word1[-3:], \n",
        "            \n",
        "            \n",
        "          '-2word.lower()': word2.lower(),\n",
        "          '-2Prefix_2':word2[:2],\n",
        "          '-2Prefix_3':word2[:3], \n",
        "          '-2word.istitle()': word2.istitle(), \n",
        "          '-2word.isupper()': word2.isupper(), \n",
        "          '-2word.islower()': word2.islower(),\n",
        "          '-2word.isdigit()': word2.isdigit(), \n",
        "          '-2word.isalpha()': word2.isalpha(), \n",
        "          '-2word.punct()': contain_punct(word2),\n",
        "          '-2word.apost()': apostrophe(word2),\n",
        "          '-2word.non_intial': non_intial(word2),\n",
        "          '-2word.mix': mix(word2),\n",
        "          '-2word.pattern()': word_pattern(word2),\n",
        "          '-2word.pattern_sum()': pattern_sum(word_pattern(word2)), \n",
        "          '-2Suffix_2':word2[-2:], \n",
        "          '-2Suffix_3':word2[-3:], \n",
        "        })\n",
        "        \n",
        "    else:\n",
        "        features['Start'] = True\n",
        "        \n",
        "    if i == len(sentence)-2:\n",
        "        '''\n",
        "        Get the token after in the sentence\n",
        "        '''\n",
        "        word1 = sentence[i+1]\n",
        "        features.update({\n",
        "          '+1word.lower()': word1.lower(),\n",
        "          '+1Prefix_2':word1[:2],\n",
        "          '+1Prefix_3':word1[:3], \n",
        "          '+1word.istitle()': word1.istitle(), \n",
        "          '+1word.isupper()': word1.isupper(), \n",
        "          '+1word.islower()': word1.islower(),\n",
        "          '+1word.isdigit()': word1.isdigit(), \n",
        "          '+1word.isalpha()': word1.isalpha(), \n",
        "          '+1word.punct()': contain_punct(word1),\n",
        "          '+1word.apost()': apostrophe(word1),\n",
        "          '+1word.non_intial': non_intial(word1),\n",
        "          '+1word.mix': mix(word1),\n",
        "          '+1word.pattern()': word_pattern(word1),\n",
        "          '+1word.pattern_sum()': pattern_sum(word_pattern(word1)), \n",
        "          '+1Suffix_2':word1[-2:], \n",
        "          '+1Suffix_3':word1[-3:], \n",
        "        })\n",
        "        \n",
        "    elif i < len(sentence)-2:\n",
        "        \n",
        "        word1 = sentence[i+1]\n",
        "        word2 = sentence[i+2]\n",
        "        \n",
        "        features.update({\n",
        "          '+1word.lower()': word1.lower(),\n",
        "          '+1Prefix_2':word1[:2],\n",
        "          '+1Prefix_3':word1[:3], \n",
        "          '+1word.istitle()': word1.istitle(), \n",
        "          '+1word.isupper()': word1.isupper(), \n",
        "          '+1word.islower()': word1.islower(),\n",
        "          '+1word.isdigit()': word1.isdigit(), \n",
        "          '+1word.isalpha()': word1.isalpha(), \n",
        "          '+1word.punct()': contain_punct(word1),\n",
        "          '+1word.apost()': apostrophe(word1),\n",
        "          '+1word.non_intial': non_intial(word1),\n",
        "          '+1word.mix': mix(word1),\n",
        "          '+1word.pattern()': word_pattern(word1),\n",
        "          '+1word.pattern_sum()': pattern_sum(word_pattern(word1)), \n",
        "          '+1Suffix_2':word1[-2:], \n",
        "          '+1Suffix_3':word1[-3:], \n",
        "            \n",
        "          '+2word.lower()': word2.lower(),\n",
        "          '+2Prefix_2':word2[:2],\n",
        "          '+2Prefix_3':word2[:3], \n",
        "          '+2word.istitle()': word2.istitle(), \n",
        "          '+2word.isupper()': word2.isupper(), \n",
        "          '+2word.islower()': word2.islower(),\n",
        "          '+2word.isdigit()': word2.isdigit(), \n",
        "          '+2word.isalpha()': word2.isalpha(), \n",
        "          '+2word.punct()': contain_punct(word2),\n",
        "          '+2word.apost()': apostrophe(word2),\n",
        "          '+2word.non_intial': non_intial(word2),\n",
        "          '+2word.mix': mix(word2),\n",
        "          '+2word.pattern()': word_pattern(word2),\n",
        "          '+2word.pattern_sum()': pattern_sum(word_pattern(word2)), \n",
        "          '+2Suffix_2':word2[-2:], \n",
        "          '+2Suffix_3':word2[-3:], \n",
        "        })\n",
        "        \n",
        "    else:\n",
        "        features['End'] = True\n",
        "    \n",
        "    return features\n",
        "\n",
        "def get_sentence(dataset,sentence_number):\n",
        "    sentence = []\n",
        "    for i in dataset[sentence_number-1]:\n",
        "        sentence.append(i[0])\n",
        "    return(sentence)\n",
        "\n",
        "\n",
        "def get_label(dataset,sentence_number):\n",
        "    sentence = []\n",
        "    for i in dataset[sentence_number-1]:\n",
        "        sentence.append(i[1])\n",
        "    return(sentence)\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def get_all_sentences(dataset):\n",
        "    sentences=[]\n",
        "    for i in range(len(dataset)):\n",
        "        sentences.append(get_sentence(dataset,i+1))\n",
        "    return sentences\n",
        "\n",
        "def get_all_labels(dataset):\n",
        "    labels=[]\n",
        "    for i in range(len(dataset)):\n",
        "        #labels.append(partial_tags(get_label(dataset,i+1)))\n",
        "        labels.append(get_label(dataset,i+1))\n",
        "    return labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E84PN1BAW3ro"
      },
      "source": [
        "#Apply feature engineering\n",
        "train_sents = get_all_sentences(train)\n",
        "train_labels = get_all_labels(train)\n",
        "test_sents = get_all_sentences(test)\n",
        "test_labels = get_all_labels(test)\n",
        "\n",
        "X_train = [sent2features(s) for s in train_sents]\n",
        "y_train = train_labels\n",
        "X_test = [sent2features(s) for s in test_sents]\n",
        "y_test = test_labels\n",
        "\n",
        "\n",
        "sub_labels=list(set([item for sublist in train_labels for item in sublist]))\n",
        "sub_labels.remove(\"O\")\n",
        "sub_labels.sort(reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXQz3yAcXCa0"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKL-2EAUr4w9"
      },
      "source": [
        "crf = CRF(\n",
        "    algorithm='lbfgs',\n",
        "    max_iterations=50,\n",
        "    c1=0.4,\n",
        "    c2=0.7,\n",
        "    all_possible_transitions=False\n",
        "\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpikYqa-wecF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b9ba6da5-8def-4cd4-cc7b-670cfcb84702"
      },
      "source": [
        "%%time\n",
        "crf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 57.3 s, sys: 404 ms, total: 57.7 s\n",
            "Wall time: 57.6 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=False,\n",
              "    averaging=None, c=None, c1=0.4, c2=0.7, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=50,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egFkXwv-YgUj"
      },
      "source": [
        "## Predict On Training Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqnhlZQ_xBtF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "254cab7c-b1c0-4555-d115-9d85786da7ad"
      },
      "source": [
        "#predict\n",
        "y_preds = crf.predict(X_train)\n",
        "\n",
        "report = flat_classification_report(y_pred=y_preds, y_true=y_train, labels=sub_labels)\n",
        "print(report)\n",
        "\n",
        "#F1 Score\n",
        "score=flat_f1_score(y_pred=y_preds, y_true=y_train, average='micro',labels=sub_labels)\n",
        "print(round(score,3))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-PER       0.99      0.99      0.99     11128\n",
            "       I-ORG       0.98      0.98      0.98     10001\n",
            "      I-MISC       0.98      0.96      0.97      4556\n",
            "       I-LOC       0.99      0.98      0.99      8286\n",
            "       B-ORG       1.00      1.00      1.00        24\n",
            "      B-MISC       1.00      0.49      0.65        37\n",
            "       B-LOC       1.00      0.82      0.90        11\n",
            "\n",
            "   micro avg       0.98      0.98      0.98     34043\n",
            "   macro avg       0.99      0.89      0.93     34043\n",
            "weighted avg       0.98      0.98      0.98     34043\n",
            "\n",
            "0.983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuDpKItjYilS"
      },
      "source": [
        "## Predict On Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk_jG6Q_K3CC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "fcff1619-662b-41be-fb92-e595ae6d541e"
      },
      "source": [
        "#predict\n",
        "y_preds = crf.predict(X_test)\n",
        "\n",
        "report = flat_classification_report(y_pred=y_preds, y_true=y_test, labels=sub_labels)\n",
        "print(report)\n",
        "\n",
        "#F1 Score\n",
        "f1_score=flat_f1_score(y_pred=y_preds, y_true=y_test, average='micro',labels=sub_labels)\n",
        "recall_score = flat_recall_score(y_pred=y_preds, y_true=y_test, average='micro', labels=sub_labels)\n",
        "pre_score = flat_precision_score(y_pred=y_preds, y_true=y_test, average='micro', labels=sub_labels)\n",
        "print(\"Precision score: %.2f\" %round(pre_score*100,3))\n",
        "print(\"Recall score: %.2f\" %round(recall_score*100,3))\n",
        "print(\"F1 score: %.2f\" %round(f1_score*100,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       I-PER       0.87      0.90      0.88      2773\n",
            "       I-ORG       0.79      0.79      0.79      2491\n",
            "      I-MISC       0.73      0.75      0.74       909\n",
            "       I-LOC       0.87      0.86      0.86      1919\n",
            "       B-ORG       0.00      0.00      0.00         5\n",
            "      B-MISC       0.00      0.00      0.00         9\n",
            "       B-LOC       0.00      0.00      0.00         6\n",
            "\n",
            "   micro avg       0.83      0.84      0.83      8112\n",
            "   macro avg       0.47      0.47      0.47      8112\n",
            "weighted avg       0.83      0.84      0.83      8112\n",
            "\n",
            "Precision score: 82.98\n",
            "Recall score: 83.53\n",
            "F1 score: 83.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cBJe8sCVVy8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "68db9531-e31e-4b4e-97ea-78dd8a14eabf"
      },
      "source": [
        "from google.colab import files\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "sub_labels.append(\"O\")\n",
        "flat_preds = [item for sublist in y_preds for item in sublist]\n",
        "flat_true = [item for sublist in y_test for item in sublist]\n",
        "matrix=confusion_matrix(flat_preds,flat_true, labels=sub_labels)\n",
        "\n",
        "cm = pd.DataFrame(matrix, columns = sub_labels, index=sub_labels)\n",
        "\n",
        "cm.to_csv('W2_matrix_.csv')\n",
        "files.download('W2_matrix_.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_57f9e0c0-eef4-429e-90f9-d1429ad54500\", \"W2_matrix_.csv\", 263)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}