{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Average Bi-LSTM-CRF (GLOVE 50D)",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deanhoperobertson/Named-Enitty-Recognition/blob/master/Models/Final%20Models/BiLSTM-CRF/GloVe/Average%20BiLSTM-CRF%20(GloVe).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEI15-hK3sQ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "d0b3c544-5b6c-499b-df53-10709cdbc1af"
      },
      "source": [
        "!sudo pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "!pip install sklearn_crfsuite\n",
        "!pip install keras==2.2.4\n",
        "%tensorflow_version 1.x\n",
        "#!pip install tensorflow-gpu==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-tadfn9cs\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-tadfn9cs\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-contrib==2.0.8 from git+https://www.github.com/keras-team/keras-contrib.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.15.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=af1dfd5d0289ca7e2731432003c84dbdff4f5a148e3092a842e1f261214ee9bb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4d6rnanq/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvLtrysY3xZn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "13339e9f-350c-4cb8-dd48-f4c91dbc8f33"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "\n",
        "#keras and tensorflow packages\n",
        "import tensorflow as tf\n",
        "from keras.layers.merge import add\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from keras_contrib.layers import CRF\n",
        "from keras_contrib.losses import crf_loss\n",
        "from keras_contrib.metrics import crf_viterbi_accuracy\n",
        "from keras_contrib.metrics import crf_accuracy\n",
        "\n",
        "#evaluation\n",
        "from sklearn_crfsuite.metrics import flat_classification_report,flat_f1_score,flat_precision_score, flat_recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeDhXk5P_S_r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec682514-04d7-41f1-d9a4-c6898e276d66"
      },
      "source": [
        "#Ensure Reproducibility\n",
        "import numpy as np\n",
        "import random as rn\n",
        "import os\n",
        "\n",
        "random_seed=3\n",
        "\n",
        "# 1) set numpy random seed\n",
        "np.random.seed(random_seed)\n",
        "# 2) set build-in random seed\n",
        "rn.seed(random_seed)\n",
        "# 3) set PYTHONHASHSEED\n",
        "os.environ['PYTHONHASHSEED']=str(random_seed)\n",
        "# 4) set tensorflow random seed\n",
        "tf.random.set_random_seed(random_seed)\n",
        "\n",
        "# 5) Force TensorFlow to use single thread.\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "from keras import backend as K\n",
        "tf.set_random_seed(1)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ5UL1PL39-g"
      },
      "source": [
        "#import data from my github repo\n",
        "train_url = \"https://raw.githubusercontent.com/deanhoperobertson/Named-Enitty-Recognition/master/Data/train.txt\"\n",
        "test_url = \"https://raw.githubusercontent.com/deanhoperobertson/Named-Enitty-Recognition/master/Data/test.txt\"\n",
        "train = urllib.request.urlopen(train_url).read()\n",
        "test = urllib.request.urlopen(test_url).read()\n",
        "train = train.decode('utf-8')\n",
        "test = test.decode('utf-8')\n",
        "\n",
        "def readstring(filename, meth):\n",
        "    f = filename.split('\\n')\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for line in f:\n",
        "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
        "            if len(sentence) > 0:\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "            continue\n",
        "        splits = line.split(' ')\n",
        "        if meth.lower()==\"numbers1\":\n",
        "            sentence.append([hasNumbers1(splits[0]), splits[-1].strip()])\n",
        "        elif meth.lower()==\"numbers2\":\n",
        "            sentence.append([hasNumbers2(splits[0]), splits[-1].strip()])\n",
        "        else:\n",
        "            sentence.append([splits[0], splits[-1].strip()])\n",
        "    if len(sentence) > 0:\n",
        "        sentences.append(sentence)\n",
        "        sentence = []\n",
        "    return sentences\n",
        "\n",
        "def hasNumbers1(inputString):\n",
        "    if re.search(r'\\d', inputString):\n",
        "        return \"0\"\n",
        "    else:return(inputString)\n",
        "\n",
        "def hasNumbers2(text):\n",
        "  if text.isdigit():\n",
        "      return \"1\"\n",
        "  elif re.search(r'\\d',text) and re.search(r'\\,|\\.',text):\n",
        "      return \"1\" \n",
        "  else:\n",
        "      if re.search(r'\\d', text):\n",
        "          return(re.sub('\\d','D', text))\n",
        "      else:\n",
        "          return text\n",
        "\n",
        "#preproces the txt file\n",
        "train_data = readstring(train,\"Numbers1\")\n",
        "test_data = readstring(test,\"Numbers1\")\n",
        "\n",
        "#create corpus\n",
        "corpus = train_data.copy()\n",
        "corpus.extend(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQSami9V4FbD"
      },
      "source": [
        "def reformat_data(data,meth):\n",
        "  if meth.lower() == \"data\":\n",
        "    i=0\n",
        "  else: i=1\n",
        "  train = []\n",
        "  output= []\n",
        "  for sentence in data:\n",
        "    words=[]\n",
        "    for x in sentence:\n",
        "      words.append(x[i])\n",
        "    train.append(words)\n",
        "\n",
        "  for i in train:\n",
        "    string = ' '.join(i)\n",
        "    output.append(string)\n",
        "  return output\n",
        "\n",
        "def get_max_length(corpus):\n",
        "  length = []\n",
        "  for sentence in corpus:\n",
        "    length.append(len(sentence))\n",
        "  return int(max(length))\n",
        "\n",
        "def number_of_tags(corpus):\n",
        "  tags=[]\n",
        "  for sentence in corpus:\n",
        "    for tag in sentence:\n",
        "      tags.append(tag[1])\n",
        "  return int(len(list(set(tags))))\n",
        "\n",
        "\n",
        "MAX_LEN = get_max_length(corpus)\n",
        "N_tags = number_of_tags(corpus)\n",
        "\n",
        "train = reformat_data(train_data,\"data\")\n",
        "test = reformat_data(test_data,\"data\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOyKFaZ64Piy"
      },
      "source": [
        "# create a tokenizer\n",
        "token_word = text.Tokenizer(char_level=False, lower=True, filters=\"}\", oov_token='UNK')\n",
        "token_word.fit_on_texts(train)\n",
        "\n",
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "X_train = sequence.pad_sequences(token_word.texts_to_sequences(train), maxlen=MAX_LEN,padding=\"post\")\n",
        "X_test = sequence.pad_sequences(token_word.texts_to_sequences(test), maxlen=MAX_LEN,padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "791RIPxLFdE4"
      },
      "source": [
        "train = reformat_data(train_data,\"tags\")\n",
        "test = reformat_data(test_data,\"tags\")\n",
        "\n",
        "# create a tokenizer\n",
        "token_tag = text.Tokenizer(char_level=False, lower=False, filters=\"}\")\n",
        "token_tag.fit_on_texts(train)\n",
        "\n",
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "Y = sequence.pad_sequences(token_tag.texts_to_sequences(train), maxlen=MAX_LEN,padding=\"post\")\n",
        "# One-Hot encode categorical labels\n",
        "Y_train = [to_categorical(i, num_classes=N_tags+1) for i in Y]\n",
        "\n",
        "Y = sequence.pad_sequences(token_tag.texts_to_sequences(test), maxlen=MAX_LEN,padding=\"post\")\n",
        "# One-Hot encode categorical labels\n",
        "Y_test = [to_categorical(i, num_classes=N_tags+1) for i in Y]\n",
        "\n",
        "#add padding \n",
        "token_tag.index_word[0]=\"PAD\"\n",
        "sub_label = list(token_tag.index_word.values())\n",
        "sub_label.remove('O')\n",
        "sub_label.remove('PAD')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADOS66iMHYkr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39645095-467e-4fc1-9774-0e1293028d09"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDX21YJbJy6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99bdff24-3eb3-49d6-8c3b-37718c54406d"
      },
      "source": [
        "root_path = \"/content/drive/My Drive/glove.6B.50d.txt\"\n",
        "embeddings_index={}\n",
        "f = open(root_path, encoding = \"utf-8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QCSd3QKJ-Cq"
      },
      "source": [
        "#create emedding matrix\n",
        "EMBEDDING=50\n",
        "word_index = token_word.word_index\n",
        "embedding_matrix = np.zeros((len(token_word.word_index) + 1, EMBEDDING))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "      # words not found in embedding index will be all-zeros.\n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHwzSe4s8cj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4053897-d020-4150-d958-c5d44743e538"
      },
      "source": [
        "checks=[]\n",
        "words=[]\n",
        "for i in range(0,len(token_word.word_index)+1):\n",
        "  if embedding_matrix[i][0] == 0.0:\n",
        "    checks.append(1)\n",
        "    words.append(list(token_word.word_index.items())[i-1][0])\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "print(\"Missing words from Embeddings: %d (%.2f%%)\" %(len(checks),(len(checks)/len(token_word.word_index)*100)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Missing words from Embeddings: 1218 (7.10%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLUxQqI8Md4N"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJXcEXJYMg4_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1b80605-c3e6-4e89-dcc8-fdd2af3e8c1e"
      },
      "source": [
        "%%time\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "# Paramters\n",
        "EPOCHS=20\n",
        "BATCH_SIZE = 32\n",
        "LSTM_CELLS = 200\n",
        "DROPOUT = 0.10\n",
        "HIDDEN = 100\n",
        "CLIP = 1.0\n",
        "\n",
        "#optimizer\n",
        "OPT=optimizers.Adam(clipvalue=CLIP)\n",
        "\n",
        "#number of runs\n",
        "runs = 3\n",
        "results = []\n",
        "\n",
        "#Build Model\n",
        "def create_model():\n",
        "  input =  Input(shape=(MAX_LEN,))\n",
        "\n",
        "  model_2 = Embedding(len(token_word.word_index) + 1,output_dim=EMBEDDING,\n",
        "                    weights=[embedding_matrix],input_length=MAX_LEN,\n",
        "                    trainable=False,mask_zero=True)(input)\n",
        "\n",
        "  model_2 = Bidirectional(LSTM(units=LSTM_CELLS, return_sequences=True,\n",
        "                            recurrent_dropout=DROPOUT, dropout=DROPOUT))(model_2)\n",
        "\n",
        "  model_2 = TimeDistributed(Dense(HIDDEN, activation=\"relu\"))(model_2)\n",
        "  crf = CRF(N_tags+1)  # CRF layer\n",
        "  out = crf(model_2)  # output\n",
        "  model_2 = Model(input, out)\n",
        "  model_2.compile(optimizer=OPT, loss=crf_loss,metrics=[crf_viterbi_accuracy])\n",
        "  return model_2\n",
        "\n",
        "for i in range(1,runs+1):\n",
        "  print(\"Run:\",(i))\n",
        "  model = create_model()\n",
        "  history = model.fit(X_train, np.array(Y_train), batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.2, verbose=1,callbacks=[early_stopping])\n",
        "  \n",
        "  print(\"Predicting\")\n",
        "  pred = model.predict(X_test, verbose=1)\n",
        "\n",
        "  preds = np.argmax(pred, axis=-1)\n",
        "  y_tr_true = np.argmax(Y_test, -1)\n",
        "  # Convert the index to tag\n",
        "  pred_tag = [[token_tag.index_word[i] for i in row] for row in preds]\n",
        "  y_tr_true_tag = [[token_tag.index_word[i] for i in row] for row in y_tr_true]\n",
        "\n",
        "  #basic metrics\n",
        "  f1_score=flat_f1_score(y_pred=pred_tag, y_true=y_tr_true_tag,average='micro', labels=sub_label)\n",
        "  recall_score = flat_recall_score(y_pred=pred_tag, y_true=y_tr_true_tag,average='micro', labels=sub_label)\n",
        "  pre_score = flat_precision_score(y_pred=pred_tag, y_true=y_tr_true_tag,average='micro', labels=sub_label)\n",
        "\n",
        "  #create report\n",
        "  report = flat_classification_report(y_pred=pred_tag, y_true=y_tr_true_tag, labels=sub_label, output_dict=True)\n",
        "  df = pd.DataFrame(report).transpose()\n",
        "\n",
        "  #create confusion matrix\n",
        "  flat_preds = [item for sublist in pred_tag for item in sublist]\n",
        "  flat_true = [item for sublist in y_tr_true_tag for item in sublist]\n",
        "  sub_label.append(\"O\")\n",
        "  matrix=confusion_matrix(flat_preds,flat_true, labels=sub_label)\n",
        "  cm = pd.DataFrame(matrix, columns = sub_label, index=sub_label)\n",
        "  sub_label.remove(\"O\")\n",
        "\n",
        "\n",
        "  results.append({\"Precision\":pre_score,\n",
        "                  \"Recall\": recall_score,\n",
        "                  \"F1 Score\": f1_score,\n",
        "                  \"report\": df,\n",
        "                  \"matrix\": cm,\n",
        "                  \"Run\": i})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run: 1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 11232 samples, validate on 2809 samples\n",
            "Epoch 1/20\n",
            "11232/11232 [==============================] - 231s 21ms/step - loss: 40.2768 - crf_viterbi_accuracy: 0.9078 - val_loss: 35.2625 - val_crf_viterbi_accuracy: 0.9360\n",
            "Epoch 2/20\n",
            "11232/11232 [==============================] - 230s 20ms/step - loss: 40.1019 - crf_viterbi_accuracy: 0.9496 - val_loss: 35.2041 - val_crf_viterbi_accuracy: 0.9516\n",
            "Epoch 3/20\n",
            "11232/11232 [==============================] - 228s 20ms/step - loss: 40.0630 - crf_viterbi_accuracy: 0.9599 - val_loss: 35.1849 - val_crf_viterbi_accuracy: 0.9574\n",
            "Epoch 4/20\n",
            "11232/11232 [==============================] - 226s 20ms/step - loss: 40.0394 - crf_viterbi_accuracy: 0.9666 - val_loss: 35.1735 - val_crf_viterbi_accuracy: 0.9601\n",
            "Epoch 5/20\n",
            "11232/11232 [==============================] - 228s 20ms/step - loss: 40.0242 - crf_viterbi_accuracy: 0.9701 - val_loss: 35.1639 - val_crf_viterbi_accuracy: 0.9629\n",
            "Epoch 6/20\n",
            "11232/11232 [==============================] - 228s 20ms/step - loss: 40.0120 - crf_viterbi_accuracy: 0.9738 - val_loss: 35.1598 - val_crf_viterbi_accuracy: 0.9617\n",
            "Epoch 7/20\n",
            "11232/11232 [==============================] - 229s 20ms/step - loss: 40.0028 - crf_viterbi_accuracy: 0.9762 - val_loss: 35.1572 - val_crf_viterbi_accuracy: 0.9652\n",
            "Epoch 8/20\n",
            "11232/11232 [==============================] - 229s 20ms/step - loss: 39.9961 - crf_viterbi_accuracy: 0.9784 - val_loss: 35.1545 - val_crf_viterbi_accuracy: 0.9664\n",
            "Epoch 9/20\n",
            "11232/11232 [==============================] - 230s 20ms/step - loss: 39.9898 - crf_viterbi_accuracy: 0.9807 - val_loss: 35.1567 - val_crf_viterbi_accuracy: 0.9670\n",
            "Epoch 10/20\n",
            "11232/11232 [==============================] - 229s 20ms/step - loss: 39.9851 - crf_viterbi_accuracy: 0.9821 - val_loss: 35.1554 - val_crf_viterbi_accuracy: 0.9672\n",
            "Predicting\n",
            "3453/3453 [==============================] - 23s 7ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Run: 2\n",
            "Train on 11232 samples, validate on 2809 samples\n",
            "Epoch 1/20\n",
            "11232/11232 [==============================] - 234s 21ms/step - loss: 40.1462 - crf_viterbi_accuracy: 0.9362 - val_loss: 35.1854 - val_crf_viterbi_accuracy: 0.9536\n",
            "Epoch 2/20\n",
            "11232/11232 [==============================] - 231s 21ms/step - loss: 40.0442 - crf_viterbi_accuracy: 0.9641 - val_loss: 35.1670 - val_crf_viterbi_accuracy: 0.9583\n",
            "Epoch 3/20\n",
            "11232/11232 [==============================] - 231s 21ms/step - loss: 40.0204 - crf_viterbi_accuracy: 0.9704 - val_loss: 35.1553 - val_crf_viterbi_accuracy: 0.9644\n",
            "Epoch 4/20\n",
            "11232/11232 [==============================] - 230s 20ms/step - loss: 40.0058 - crf_viterbi_accuracy: 0.9748 - val_loss: 35.1528 - val_crf_viterbi_accuracy: 0.9640\n",
            "Epoch 5/20\n",
            "11232/11232 [==============================] - 229s 20ms/step - loss: 39.9967 - crf_viterbi_accuracy: 0.9777 - val_loss: 35.1544 - val_crf_viterbi_accuracy: 0.9639\n",
            "Epoch 6/20\n",
            "11232/11232 [==============================] - 229s 20ms/step - loss: 39.9899 - crf_viterbi_accuracy: 0.9806 - val_loss: 35.1499 - val_crf_viterbi_accuracy: 0.9663\n",
            "Epoch 7/20\n",
            "11232/11232 [==============================] - 227s 20ms/step - loss: 39.9835 - crf_viterbi_accuracy: 0.9827 - val_loss: 35.1527 - val_crf_viterbi_accuracy: 0.9664\n",
            "Epoch 8/20\n",
            "11232/11232 [==============================] - 229s 20ms/step - loss: 39.9783 - crf_viterbi_accuracy: 0.9844 - val_loss: 35.1538 - val_crf_viterbi_accuracy: 0.9681\n",
            "Predicting\n",
            "3453/3453 [==============================] - 23s 7ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Run: 3\n",
            "Train on 11232 samples, validate on 2809 samples\n",
            "Epoch 1/20\n",
            "11232/11232 [==============================] - 231s 21ms/step - loss: 40.1482 - crf_viterbi_accuracy: 0.9344 - val_loss: 35.1870 - val_crf_viterbi_accuracy: 0.9529\n",
            "Epoch 2/20\n",
            "11232/11232 [==============================] - 232s 21ms/step - loss: 40.0438 - crf_viterbi_accuracy: 0.9637 - val_loss: 35.1657 - val_crf_viterbi_accuracy: 0.9575\n",
            "Epoch 3/20\n",
            "11232/11232 [==============================] - 230s 21ms/step - loss: 40.0197 - crf_viterbi_accuracy: 0.9703 - val_loss: 35.1562 - val_crf_viterbi_accuracy: 0.9623\n",
            "Epoch 4/20\n",
            "11232/11232 [==============================] - 230s 21ms/step - loss: 40.0058 - crf_viterbi_accuracy: 0.9746 - val_loss: 35.1494 - val_crf_viterbi_accuracy: 0.9633\n",
            "Epoch 5/20\n",
            "11232/11232 [==============================] - 231s 21ms/step - loss: 39.9972 - crf_viterbi_accuracy: 0.9773 - val_loss: 35.1485 - val_crf_viterbi_accuracy: 0.9658\n",
            "Epoch 6/20\n",
            "11232/11232 [==============================] - 231s 21ms/step - loss: 39.9897 - crf_viterbi_accuracy: 0.9798 - val_loss: 35.1480 - val_crf_viterbi_accuracy: 0.9678\n",
            "Epoch 7/20\n",
            "11232/11232 [==============================] - 236s 21ms/step - loss: 39.9836 - crf_viterbi_accuracy: 0.9822 - val_loss: 35.1567 - val_crf_viterbi_accuracy: 0.9665\n",
            "Epoch 8/20\n",
            "11232/11232 [==============================] - 241s 21ms/step - loss: 39.9795 - crf_viterbi_accuracy: 0.9839 - val_loss: 35.1543 - val_crf_viterbi_accuracy: 0.9680\n",
            "Predicting\n",
            "3453/3453 [==============================] - 25s 7ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2h 17min 40s, sys: 9min 10s, total: 2h 26min 50s\n",
            "Wall time: 1h 41min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsStO2u9eoPO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "766d026c-cb23-4028-8db2-a4106e36a9c6"
      },
      "source": [
        "from google.colab import files\n",
        "#df_results = pd.DataFrame(results)\n",
        "\n",
        "count = 1\n",
        "for i in results:\n",
        "  report = i[\"report\"]\n",
        "  matrix = i[\"matrix\"]\n",
        "\n",
        "  report.to_csv('Glove_report_'+str(count)+'.csv')\n",
        "  files.download('Glove_report_'+str(count)+'.csv')\n",
        "\n",
        "  matrix.to_csv('Glove_matrix_'+str(count)+'.csv')\n",
        "  files.download('Glove_matrix_'+str(count)+'.csv')\n",
        "  count +=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f0b026df-26f0-42f7-af50-b054b3bfa264\", \"Glove_report_1.csv\", 609)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5b2d369e-ecba-44ed-8034-289db9a145f1\", \"Glove_matrix_1.csv\", 263)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_77c6373d-e5da-4669-be87-f9f7adf37217\", \"Glove_report_2.csv\", 594)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a1db5346-8904-4fc0-9169-f2b5523f02a4\", \"Glove_matrix_2.csv\", 261)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a50be3c4-8dfd-43d1-9b73-2be19176d409\", \"Glove_report_3.csv\", 605)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_85a9a1fc-d371-4bcf-a16a-8129a365eb70\", \"Glove_matrix_3.csv\", 263)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "347Yhu0ZIvYZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "138cc9db-517c-463a-94cf-bcbc5e95a184"
      },
      "source": [
        "df_results = pd.DataFrame(results)\n",
        "df_results.drop(['report',\"matrix\"], axis=1, inplace=True)\n",
        "\n",
        "df_results.to_csv('Average_BiLSTM_Glove.csv')\n",
        "files.download('Average_BiLSTM_Glove.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_470664f7-179a-4831-a7b7-a220702e1bd2\", \"Average_BiLSTM_Glove.csv\", 204)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQaKn5Gv-h-S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "93e203d8-4382-4ca0-cf56-56507b4749ee"
      },
      "source": [
        "df_results.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Precision    0.852628\n",
              "Recall       0.800173\n",
              "F1 Score     0.825542\n",
              "Run          2.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH9WE3wq0S9q"
      },
      "source": [
        "df1 = results[0][\"report\"]\n",
        "for i in range(1,3):\n",
        "  df1 = df1 + results[i][\"report\"]\n",
        "\n",
        "avg_report = df1/3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eenBBErpULT6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "0fe8722a-7ee4-4d85-b080-c9fb0ca5d9c1"
      },
      "source": [
        "avg_report.sort_values(by=['support'], ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>micro avg</th>\n",
              "      <td>0.852628</td>\n",
              "      <td>0.800173</td>\n",
              "      <td>0.825542</td>\n",
              "      <td>8112.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.475440</td>\n",
              "      <td>0.446588</td>\n",
              "      <td>0.460454</td>\n",
              "      <td>8112.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.851478</td>\n",
              "      <td>0.800173</td>\n",
              "      <td>0.824824</td>\n",
              "      <td>8112.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PER</th>\n",
              "      <td>0.947096</td>\n",
              "      <td>0.870537</td>\n",
              "      <td>0.907017</td>\n",
              "      <td>2773.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ORG</th>\n",
              "      <td>0.774444</td>\n",
              "      <td>0.740131</td>\n",
              "      <td>0.756760</td>\n",
              "      <td>2491.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-LOC</th>\n",
              "      <td>0.882579</td>\n",
              "      <td>0.847316</td>\n",
              "      <td>0.864586</td>\n",
              "      <td>1919.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MISC</th>\n",
              "      <td>0.723964</td>\n",
              "      <td>0.668133</td>\n",
              "      <td>0.694816</td>\n",
              "      <td>909.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MISC</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-LOC</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ORG</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              precision    recall  f1-score  support\n",
              "micro avg      0.852628  0.800173  0.825542   8112.0\n",
              "macro avg      0.475440  0.446588  0.460454   8112.0\n",
              "weighted avg   0.851478  0.800173  0.824824   8112.0\n",
              "I-PER          0.947096  0.870537  0.907017   2773.0\n",
              "I-ORG          0.774444  0.740131  0.756760   2491.0\n",
              "I-LOC          0.882579  0.847316  0.864586   1919.0\n",
              "I-MISC         0.723964  0.668133  0.694816    909.0\n",
              "B-MISC         0.000000  0.000000  0.000000      9.0\n",
              "B-LOC          0.000000  0.000000  0.000000      6.0\n",
              "B-ORG          0.000000  0.000000  0.000000      5.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgjIaCPqSfrt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}