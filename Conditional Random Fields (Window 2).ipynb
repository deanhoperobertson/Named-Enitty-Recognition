{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Random Field Model (Window 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "#Custom models\n",
    "from prepro import readfile, get_sentence, is_number, extract_words,get_label,partial_tags\n",
    "\n",
    "#Model\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "#Evalulation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn_crfsuite.metrics import flat_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from my github repo\n",
    "test = readfile(\"test.txt\")\n",
    "train =readfile(\"train.txt\")\n",
    "\n",
    "# filenames = ['train.txt', 'valid.txt']\n",
    "# with open('Combined.txt', 'w') as outfile:\n",
    "#     for fname in filenames:\n",
    "#         with open(fname) as infile:\n",
    "#             for line in infile:\n",
    "#                 outfile.write(line)\n",
    "                \n",
    "# train =readfile(\"Combined.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthographic Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special Features:\n",
    "def count_vowel(word):\n",
    "    '''\n",
    "    Function returns the number of vowels in token\n",
    "    '''\n",
    "    return sum(list(map(word.lower().count, \"aeiou\")))\n",
    "\n",
    "def dash(word):\n",
    "    '''\n",
    "    The Function returns whether or not the token contains a dash\n",
    "    '''\n",
    "    return 1 if \"-\" in word else 0\n",
    "\n",
    "def count_consonants(word):\n",
    "    '''\n",
    "    The Function returns the number of consonants in a token\n",
    "    '''\n",
    "    vowels=\"aeiou\"\n",
    "    return sum(i not in vowels for i in word)\n",
    "\n",
    "def contain_punct(word):\n",
    "    '''\n",
    "    The Function returns the boolean if punctuations is present in token\n",
    "    '''\n",
    "    if re.match(r'^\\w+$',word):return False\n",
    "    else: return True\n",
    "    \n",
    "def apostrophe(word):\n",
    "    '''\n",
    "    The Function returns boolean if \"'s\" is present in token \n",
    "    '''\n",
    "    if word ==\"'s\":return True\n",
    "    else:return False\n",
    "    \n",
    "def word_pattern(word):\n",
    "    '''\n",
    "    The Function returns word patter feature\n",
    "    Upper Case = \"A\"\n",
    "    Lower Case = \"a\"\n",
    "    Digit = \"0\"\n",
    "    '''\n",
    "    token=\"\"\n",
    "    for i in word:\n",
    "        if i.isupper():\n",
    "            token +=\"A\"\n",
    "        elif i.islower():\n",
    "            token +=\"a\"\n",
    "        elif i.isdigit():\n",
    "            token +=\"0\"\n",
    "        else:\n",
    "            token +=str(i)\n",
    "    return token\n",
    "\n",
    "def pattern_sum(word):\n",
    "    '''\n",
    "    The Function returns the word patern without consectutive duplicates\n",
    "    '''\n",
    "    return ''.join(OrderedDict.fromkeys(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sentence,i):\n",
    "    word = sentence[i]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'Prefix_2': word[:2], # prefix\n",
    "        'Prefix_3': word[:3], # prefix\n",
    "        \n",
    "        'word.isupper()': word.isupper(), #all caps\n",
    "        'word.islower()': word.islower(),# all lower case\n",
    "        'word.istitle()': word.istitle(), #starts with caps\n",
    "        'word.isdigit()': word.isdigit(), #all digits\n",
    "        'word.isalpha()': word.isalpha(), #all letters\n",
    "        'word.isalnum()': word.isalnum(), #mixture of letters and digits\n",
    "        \n",
    "        'word.pattern()': word_pattern(word),#word pattern\n",
    "        'word.pattern_sum()': pattern_sum(word_pattern(word)),\n",
    "        'word.punct()':contain_punct(word),#contains punctuation\n",
    "        'word.apost()':apostrophe(word), #is an apostrophe\n",
    "        \n",
    "        'Suffix_2': word[-2:], # suffix\n",
    "        'Suffix_3': word[-3:], # suffix\n",
    "    }\n",
    "    if  i == 1 :\n",
    "        '''\n",
    "        Get the token before in the sentence\n",
    "        '''\n",
    "        word1 = sentence[i-1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word Prefix_2': word1[:2],\n",
    "            '-1:word Prefix_3': word1[:3], \n",
    "            \n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.islower()': word1.lower(),\n",
    "            '-1:word.isdigit()': word1.isdigit(),\n",
    "            '-1:word.isalpha()': word1.isalpha(),\n",
    "            '-1:word.isalnum()': word1.isalnum(),\n",
    "            \n",
    "            '-1:word.pattern()': word_pattern(word1),\n",
    "            '-1:word.pattern_sum()': pattern_sum(word_pattern(word1)),\n",
    "            '-1:word.punct()':contain_punct(word1),\n",
    "            '-1:word.apost()':apostrophe(word1),\n",
    "            \n",
    "            '-1:word.Suffix_2': word1[-2:],\n",
    "            '-1:word.Suffix_3': word1[-3:],\n",
    "        })\n",
    "        \n",
    "    elif i>1 :\n",
    "        word1 = sentence[i-1]\n",
    "        word2 = sentence[i-2]\n",
    "        \n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word Prefix_2': word1[:2],\n",
    "            '-1:word Prefix_3': word1[:3], \n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:word.islower()': word1.lower(),\n",
    "            '-1:word.isdigit()': word1.isdigit(),\n",
    "            '-1:word.isalpha()': word1.isalpha(),\n",
    "            '-1:word.isalnum()': word1.isalnum(),\n",
    "            '-1:word.pattern()': word_pattern(word1),\n",
    "            '-1:word.pattern_sum()': pattern_sum(word_pattern(word1)),\n",
    "            '-1:word.punct()':contain_punct(word1),\n",
    "            '-1:word.apost()':apostrophe(word1),\n",
    "            '-1:word.Suffix_2': word1[-2:],\n",
    "            '-1:word.Suffix_3': word1[-3:],\n",
    "            \n",
    "            \n",
    "            \n",
    "            '-2:word.lower()': word2.lower(),\n",
    "            '-2:word Prefix_2': word2[:2],\n",
    "            '-2:word Prefix_3': word2[:3], \n",
    "            '-2:word.istitle()': word2.istitle(),\n",
    "            '-2:word.isupper()': word2.isupper(),\n",
    "            '-2:word.islower()': word2.lower(),\n",
    "            '-2:word.isdigit()': word2.isdigit(),\n",
    "            '-2:word.isalpha()': word2.isalpha(),\n",
    "            '-2:word.isalnum()': word2.isalnum(),\n",
    "            '-2:word.pattern()': word_pattern(word2),\n",
    "            '-2:word.pattern_sum()': pattern_sum(word_pattern(word2)),\n",
    "            '-2:word.punct()':contain_punct(word2),\n",
    "            '-2:word.apost()':apostrophe(word2),\n",
    "            '-2:word.Suffix_2': word2[-2:],\n",
    "            '-2:word.Suffix_3': word2[-3:],\n",
    "        })\n",
    "        \n",
    "    else:\n",
    "        features['Start'] = True\n",
    "        \n",
    "    if i == len(sentence)-2:\n",
    "        '''\n",
    "        Get the token after in the sentence\n",
    "        '''\n",
    "        word1 = sentence[i+1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word Prefix_2': word1[:2],\n",
    "            '+1:word Prefix_3': word1[:3], \n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.islower()': word1.lower(),\n",
    "            '+1:word.isdigit()': word1.isdigit(),\n",
    "            '+1:word.isalpha()': word1.isalpha(),\n",
    "            '+1:word.isalnum()': word1.isalnum(),\n",
    "            '+1:word.pattern()': word_pattern(word1),\n",
    "            '+1:word.pattern_sum()': pattern_sum(word_pattern(word1)),\n",
    "            '+1:word.punct()':contain_punct(word1),\n",
    "            '+1:word.apost()':apostrophe(word1),\n",
    "            '+1:word.Suffix_2': word1[-2:],\n",
    "            '+1:word.Suffix_3': word1[-3:],\n",
    "        })\n",
    "        \n",
    "    elif i < len(sentence)-2:\n",
    "        \n",
    "        word1 = sentence[i+1]\n",
    "        word2 = sentence[i+2]\n",
    "        \n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word Prefix_2': word1[:2],\n",
    "            '+1:word Prefix_3': word1[:3], \n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:word.islower()': word1.lower(),\n",
    "            '+1:word.isdigit()': word1.isdigit(),\n",
    "            '+1:word.isalpha()': word1.isalpha(),\n",
    "            '+1:word.isalnum()': word1.isalnum(),\n",
    "            '+1:word.pattern()': word_pattern(word1),\n",
    "            '+1:word.pattern_sum()': pattern_sum(word_pattern(word1)),\n",
    "            '+1:word.punct()':contain_punct(word1),\n",
    "            '+1:word.apost()':apostrophe(word1),\n",
    "            '+1:word.Suffix_2': word1[-2:],\n",
    "            '+1:word.Suffix_3': word1[-3:],\n",
    "            \n",
    "            '+2:word.lower()': word2.lower(),\n",
    "            '+2:word Prefix_2': word2[:2],\n",
    "            '+2:word Prefix_3': word2[:3], \n",
    "            '+2:word.istitle()': word2.istitle(),\n",
    "            '+2:word.isupper()': word2.isupper(),\n",
    "            '+2:word.islower()': word2.lower(),\n",
    "            '+2:word.isdigit()': word2.isdigit(),\n",
    "            '+2:word.isalpha()': word2.isalpha(),\n",
    "            '+2:word.isalnum()': word2.isalnum(),\n",
    "            '+2:word.pattern()': word_pattern(word2),\n",
    "            '+2:word.pattern_sum()': pattern_sum(word_pattern(word2)),\n",
    "            '+2:word.punct()':contain_punct(word2),\n",
    "            '+2:word.apost()':apostrophe(word2),\n",
    "            '+2:word.Suffix_2': word2[-2:],\n",
    "            '+2:word.Suffix_3': word2[-3:],\n",
    "        })\n",
    "        \n",
    "    else:\n",
    "        features['End'] = True\n",
    "    \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def get_all_sentences(dataset):\n",
    "    sentences=[]\n",
    "    for i in range(len(dataset)):\n",
    "        sentences.append(get_sentence(dataset,i+1))\n",
    "    return sentences\n",
    "\n",
    "def get_all_labels(dataset):\n",
    "    labels=[]\n",
    "    for i in range(len(dataset)):\n",
    "        #labels.append(partial_tags(get_label(dataset,i+1)))\n",
    "        labels.append(get_label(dataset,i+1))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "#get the first sentence\n",
    "sent = get_sentence(train,1)\n",
    "#label = partial_tags(get_label(train,1))\n",
    "label = get_label(train,1)\n",
    "\n",
    "#print out first sentence\n",
    "print(sent)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applt feature engineering\n",
    "train_sents = get_all_sentences(train)\n",
    "train_labels = get_all_labels(train)\n",
    "test_sents = get_all_sentences(test)\n",
    "test_labels = get_all_labels(test)\n",
    "\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = train_labels\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = test_labels\n",
    "\n",
    "\n",
    "sub_labels=list(set([item for sublist in train_labels for item in sublist]))\n",
    "sub_labels.remove(\"O\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Condtional Random Field Model\n",
    "\n",
    "### Model 1\n",
    "- Using Stochastic Gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-MISC       0.97      0.89      0.93        37\n",
      "       B-LOC       1.00      1.00      1.00        11\n",
      "      I-MISC       1.00      1.00      1.00      4556\n",
      "       I-ORG       1.00      1.00      1.00     10001\n",
      "       B-ORG       1.00      1.00      1.00        24\n",
      "       I-LOC       1.00      1.00      1.00      8286\n",
      "       I-PER       1.00      1.00      1.00     11128\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     34043\n",
      "   macro avg       1.00      0.98      0.99     34043\n",
      "weighted avg       1.00      1.00      1.00     34043\n",
      "\n",
      "0.9996034135808817\n",
      "Wall time: 48.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf4 = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.2,\n",
    "          max_iterations=50,\n",
    "          all_possible_transitions=False)\n",
    "\n",
    "#training model\n",
    "crf4.fit(X=X_train, y=y_train)\n",
    "\n",
    "#generate predictions\n",
    "pred = crf4.predict(X_train)\n",
    "\n",
    "#generate report on entire model\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_train,labels=sub_labels)\n",
    "print(report)\n",
    "\n",
    "score=flat_f1_score(y_pred=pred, y_true=y_train,average='micro',labels=sub_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhoperoberts\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-MISC       0.00      0.00      0.00         9\n",
      "       B-LOC       0.00      0.00      0.00         6\n",
      "      I-MISC       0.75      0.78      0.76       909\n",
      "       I-ORG       0.81      0.80      0.81      2491\n",
      "       B-ORG       0.00      0.00      0.00         5\n",
      "       I-LOC       0.85      0.87      0.86      1919\n",
      "       I-PER       0.89      0.89      0.89      2773\n",
      "\n",
      "   micro avg       0.84      0.85      0.84      8112\n",
      "   macro avg       0.47      0.48      0.47      8112\n",
      "weighted avg       0.84      0.85      0.84      8112\n",
      "\n",
      "0.8432179952061951\n"
     ]
    }
   ],
   "source": [
    "#prediction with best performaning model\n",
    "pred = crf4.predict(X_test)\n",
    "\n",
    "#generate report on entire model\n",
    "report = flat_classification_report(y_pred=pred, y_true=y_test,labels=sub_labels)\n",
    "print(report)\n",
    "\n",
    "score=flat_f1_score(y_pred=pred, y_true=y_test,average='micro',labels=sub_labels)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
